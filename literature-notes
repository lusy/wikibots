\cite{DanaherEtAl2017}
# Danaher, J., Hogan, M. J., Noone, C., Kennedy, R., Behan, A., De Paor, A., et al. (2017). Algorithmic governance: Developing a research agenda through the power of collective intelligence:. Big Data & Society, 4(2), 205395171772655. http://doi.org/10.1177/2053951717726554


--> scrutinise effectiveness and legitimacy of algorithmic governance systems
--> propose a framework for researching these
--> "detailed map of key research themes, questions and methods" <-- vgl Latour
"The workshop brought together a multidisciplinary group of scholars to consider
(a) barriers to legitimate and effective algorithmic governance and
(b) the research methods needed to address the nature and impact of specific barriers."
--> "longer historical trend towards the mechanisation of governance"
--> "The systems we consider in this paper and
that we considered at our workshop are different from
their historical forebears. The differences are largely a
matter of degree and not of type."

top-down vs bottom-up algorithms: machine learning as an example of bottom-up: problem: lack of transparency, incorporated into already opaque governance structures

Checkout Kitchin research framework (p.5)

"Participants also suggested that we identify capacity-
related problems by analysing existing code and cate-
gorizing errors that emerge from this code according to
whether they are ‘technical’ or ‘legal’ in nature."

===================================================

\cite{MuellerBirn2014}

Aim:
- overview on various edit types bots carry out
- general reasons why wikipedia community uses bots
- how they organise machine tasks to provide a sustainable service

2 main groups:
- community services : create reports
- guidelines/policies : adding templates to pages

up-to-date (when?) 3 categories of research on bots:
- used as a tool for collecting data
- installed to reach Wikipedia editors in an automatic way to influence their
  editing behaviour
- bots considered as noise on the data/not important for further analysis

check Geiger(2009):
"how a weak but preexisting social norm was controversially reified into a
technological actor"

2010: 40% of newcommers' contributions rejected based on automatic tools <---
counter productive in engaging new contributors

attitudes towards bot usage changed over time
at the beginning: "One of Wikipedia's rules to consider: avoid using bots"
with time: more and more acceptance; beaurocracy; difficult for new commers to
engage

Overview: Bot Approval Group, Bot Policy, Requests for approval

methodology: select all approved task requests: try to infer bots' tasks from
them

statistics:
%TODO: check graphic in color
- proportion of bot edits grow compared to human editors

- bots edits are of support/maintenance nature
- a lot, compared to human edits, no content;
- at some point excluded from recent changes logs (is that so? today, they are
  there again, I'd say)

"Bots as community servers and rule enforcers"
"Bots are responsible that existing guidelines and policies are enforced at a
large scale."

%TODO: copy categories + conclusions from section 3.3
%TODO: literatur durchforsten

=======================================00

\cite{Geiger2017}

situated in critical algorithmic studies, critical data studies,
discusses issues in fairness, accountability and transparency

(algorithmic) governance
gatekeeping

"the organizational culture of Wikipedia is deeply intertwined with various data-driven algorithmic
systems, which Wikipedians rely on to help manage and govern the ‘‘anyone can edit’’ encyclopedia at a massive
scale."
"These bots, scripts, tools, plugins, and dashboards make Wikipedia more efficient for those who know how
to work with them, but like all organizational culture, newcomers must learn them if they want to fully participate."

Beschreibt die Prozesse für 2 verschiedene, oft vorkommende Edit-Abläufe, mit den Bots und automatischen Tools, die diese unterstützen
* editting (your own) page on Wikipedia: Conflict of interest requests --> newcommers werden hier abgeschreckt
* Speedy Deletion

"But I realized that the more interesting question is why I had so internalized this socio-techni-
cal assemblage and the values it enacts." // People internalise the way a system works and stop questioning it!!

"They are deeply imbued with particular values, prin-
ciples, norms, and ideals, and learning them is not
just about technical competency, but also socialization
into a complex organizational culture"

Some descriptive statistics:
"In the English-language Wikipedia, 22 of the 25 most active editors (by
number of edits) are bot accounts, and July 2017, they made about 20% of all edits to encyclopedia articles."
--> vgl: https://quarry.wmflabs.org/query/20703

What does it take to be a Wikipedian:
"when that partici-
pation requires not only learning Wikipedia-specific
jargon, norms, style guides, and rules, but also learning
how to interact with all the bots and power tools"

"Wikipedia demonstrates how the issues in and around
algorithmic systems are as much social as they are tech-
nical, going far beyond the opacities that arise around
proprietary source code. My argument extends Burrell’s
(2016) discussion of three different forms of opacity in
machine learning: intentional secrecy (proprietary
source code), technical literacy (such as learning to
read code), and opacities inherent in machine learning
(such as issues of interpretability). To these forms, I add
another: the opacities in learning a particular institu-
tional or organizational culture that is supported by
algorithmic systems."
// source is open, but who can actually read it? and is willing to invest the time and energy in order to hold the system accountable?
// vgl auch Gedanke von Claudia: "Wikipedia is spannend, weil wir daran das erforschen können, was wir an Facebook nicht können. Und weil die ein Abbild der Gesellschaft im Kleinen ist."
// vgl auch Web Science def: observe micro behaviours in order to study macro phenomenons (governance, ..)

Def "algorithmic": "as involving encoded proced-
ures, which are typically—but not exclusively—compu-
tationally implemented."

"Like all algorithmic systems, the ones I studied in
Wikipedia were designed, developed, and deployed by
people." //all developers are human and all humans make mistakes^^

"As Gillespie (2014) argues: ‘‘A socio-
logical analysis must not conceive of algorithms as
abstract, technical achievements, but must unpack the
warm human and institutional choices that lie behind
these cold mechanisms.’’"

Seaver (2013: 9–10) Def Algorithmic System:
"It is not the algorithm, narrowly defined, that has
sociocultural effects, but algorithmic systems — intri-
cate, dynamic arrangements of people and code. . .
When we realize that we are not talking about algo-
rithms in the technical sense, but rather algorithmic
systems of which code strictu sensu is only a part,
their defining features reverse: instead of formality,
rigidity, and consistency, we find flux, revisability,
and negotiation."
"In this context, I ask: for whom are algorithmic systems
(and the organizations that rely on them) formal, rigid,
and consistent, and for whom are they in flux, revisable,
and negotiable?" //Vorwissen, das die Menschen mitbringen, ist wichtig!

2nd level digital divide:
"who had
the knowledge, skills, and sense of empowerment to use
the Internet in ways that further engaged, empowered,
and benefitted their lives." nach Hargittai 2002

Everything's open:
"We must look at more than the fact that partici-
pation in Wikipedia is open to the public; that the infra-
structure supporting it is open sourced; and that the
community’s policies, procedures, and norms are docu-
mented in thousands and thousands of pages of text."

BUT
"We must also look at what kind of skills, knowledge, and
investment is required to fully and successfully partici-
pate,"

speaks of deletion of substandard encyclopedi articles: Where and how are the standards defined? Who defines them?

"article about a
website fails the A7 criteria in the CSD process,
which demands that articles ‘‘credibly indicate the
importance or significance of the subject.’’ (A majority
of speedy deleted articles are tagged with templates
containing A7 rationales (Geiger and Ford, 2011).)"
// ich finde dieses Kriterium ist äußerst mit Vorsicht zu genießen, da die Tür weit aufgemacht wird für Sexismus, Rassismus und andere Arten von Diskriminierung von Inhalten, die der Mehrheit von white dudes nicht passen

"Yet I had a
second, subtler motivation, hoping that in properly
demonstrating correct usage of such a template within
the established workflow of this process, I would be
made legible as a Wikipedian who knew the CSD pro-
cess and should be given some more leeway—unlike
most of the people who were creating articles that
they were deleting." //making use of the brocode^^

"Such systems do not eliminate the need for human
labor, but instead transform the kind of work that
takes place,"

erwähnt auch Abschrecken von newcommers

"As
Seaver (2013) notes with his critiques of various ‘‘crit-
ical algorithms studies’’ literature, it is easy to slip into
a mode of analysis where social factors are contextua-
lized, while infrastructure remain static and determin-
ing. Such an approach ‘‘keeps algorithms themselves
untouched, objective stones tossed about in a roily
social stream’’ (10)."

"the algorithmic
systems themselves are constructed, negotiated, contex-
tualized, and differently interpreted and enacted." // aber wer kann beim Aushandeln mitmachen?

"Wikipedia’s computational infrastructure is
also designed and governed in a relatively open
manner by the project’s volunteer community of edi-
tors (Forte and Bruckman , 2008; Gilbert and Zachry,
2015; Kennedy, 2010), unlike most of the automated
systems that are increasingly prevalent in digitally
mediated environments." //jup. und selbst da blick man nicht durch

Requirements/Expectations for bot developers:
"bot developers are generally expected to be responsive
to reasonable requests and concerns from the
community."

"Wikipedians discuss and debate
about what kinds of bots should exist in the project,"

"one of the
paradoxes of openness is that it can take substantial
time, energy, investment, and resources to fully take
advantage of all the materials released"

Veterans vs newcomers:
"they make it far easier for veteran Wikipedians to
engage in the kind of specific, complex, multifacted
work involved in the governance of Wikipedia. This
can make it far more difficult for newcomers to partici-
pate—not necessarily because bots, algorithms, or
assisted tools are inherently difficult to deal with, but
rather because bots support more complex kinds of gov-
ernance practices in Wikipedia, and complex govern-
ance practices are difficult for newcomers."

=========================================

\cite{GeiHal2017}

replicate + refute earlier results (of the paper "Even Good Bots Fight")
methods: combi: qualitative + quantitative
trace ethnography
operationalise conflict!
distinguish conflict from non-conflict in bot reverts
compile data set + meta data
background: wikipedia researchers + long-time contributors
findings: overwhelming majority of the reverts are routine collaborative work between bots
metrics: time between reverts; number of reverts per article for the same bot pair
classify patterns in edit summaries

research question: "to what extent are bot-bot reverts
in Wikipedia genuine conflicts where disagreements about how Wikipedia ought to be written were
embedded in opposing bot codebases, versus cases like Shoreland’s Addbot that reflect the opposite?"

Out of context Addbot's edits seem like a bot ran rampart.
In context it's been tons of useful work.
Do not tear data out of context!

"The EGBF paper operationalized
bot-bot conflict through reverts, which is when one user account undoes another user account’s
edit." // Geiger+Halfaker operationalisieren den Begriff differenzierter

Literature Review: bis dato Arbeiten zu bot feedback; und criticism about driving away newcomers; aber keine Forschung hat Revert Wars thematisiert;

conflict: not necessary negative, but can be generative and stimulating (avoid filter bubbles) if resolved in a respectful manner

Conflict typology:
task conflict
process conflict
relationship conflict

Types of reverts:
identity revert: "as bringing it back to an exact previous state"
partial revert: "part of an edit is removed"
declarative revert: "when a user leaves a note in an edit summary stating that they are reverting the edit (matching “rv” or “revert”)."

"They note a single revert is not indicative
of conflict, but repeated back-and-forth reverts are indicative of an edit war"

"The “Bold, Revert, and Discuss”
cycle (one of the most widely-cited essays [31] in English Wikipedia) states that editors ought to
be bold in making changes, feel free to revert others’ changes that they find unacceptable, then
discuss the issue" // kommt mir iwie netter vor, erst zu diskutieren, dann zu löschen
