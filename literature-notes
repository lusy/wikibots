\cite{DanaherEtAl2017}
# Danaher, J., Hogan, M. J., Noone, C., Kennedy, R., Behan, A., De Paor, A., et al. (2017). Algorithmic governance: Developing a research agenda through the power of collective intelligence:. Big Data & Society, 4(2), 205395171772655. http://doi.org/10.1177/2053951717726554


--> scrutinise effectiveness and legitimacy of algorithmic governance systems
--> propose a framework for researching these
--> "detailed map of key research themes, questions and methods" <-- vgl Latour
"The workshop brought together a multidisciplinary group of scholars to consider
(a) barriers to legitimate and effective algorithmic governance and
(b) the research methods needed to address the nature and impact of specific barriers."
--> "longer historical trend towards the mechanisation of governance"
--> "The systems we consider in this paper and
that we considered at our workshop are different from
their historical forebears. The differences are largely a
matter of degree and not of type."

top-down vs bottom-up algorithms: machine learning as an example of bottom-up: problem: lack of transparency, incorporated into already opaque governance structures

Checkout Kitchin research framework (p.5)

"Participants also suggested that we identify capacity-
related problems by analysing existing code and cate-
gorizing errors that emerge from this code according to
whether they are ‘technical’ or ‘legal’ in nature."

===================================================

\cite{MuellerBirn2014}

Aim:
- overview on various edit types bots carry out
- general reasons why wikipedia community uses bots
- how they organise machine tasks to provide a sustainable service

2 main groups:
- community services : create reports
- guidelines/policies : adding templates to pages

up-to-date (when?) 3 categories of research on bots:
- used as a tool for collecting data
- installed to reach Wikipedia editors in an automatic way to influence their
  editing behaviour
- bots considered as noise on the data/not important for further analysis

check Geiger(2009):
"how a weak but preexisting social norm was controversially reified into a
technological actor"

2010: 40% of newcommers' contributions rejected based on automatic tools <---
counter productive in engaging new contributors

attitudes towards bot usage changed over time
at the beginning: "One of Wikipedia's rules to consider: avoid using bots"
with time: more and more acceptance; beaurocracy; difficult for new commers to
engage

Overview: Bot Approval Group, Bot Policy, Requests for approval

methodology: select all approved task requests: try to infer bots' tasks from
them

statistics:
%TODO: check graphic in color
- proportion of bot edits grow compared to human editors

- bots edits are of support/maintenance nature
- a lot, compared to human edits, no content;
- at some point excluded from recent changes logs (is that so? today, they are
  there again, I'd say)

"Bots as community servers and rule enforcers"
"Bots are responsible that existing guidelines and policies are enforced at a
large scale."

%TODO: copy categories + conclusions from section 3.3
%TODO: literatur durchforsten

=======================================00

\cite{Geiger2017}

situated in critical algorithmic studies, critical data studies,
discusses issues in fairness, accountability and transparency

(algorithmic) governance
gatekeeping

"the organizational culture of Wikipedia is deeply intertwined with various data-driven algorithmic
systems, which Wikipedians rely on to help manage and govern the ‘‘anyone can edit’’ encyclopedia at a massive
scale."
"These bots, scripts, tools, plugins, and dashboards make Wikipedia more efficient for those who know how
to work with them, but like all organizational culture, newcomers must learn them if they want to fully participate."

Beschreibt die Prozesse für 2 verschiedene, oft vorkommende Edit-Abläufe, mit den Bots und automatischen Tools, die diese unterstützen
* editting (your own) page on Wikipedia: Conflict of interest requests --> newcommers werden hier abgeschreckt
* Speedy Deletion

"But I realized that the more interesting question is why I had so internalized this socio-techni-
cal assemblage and the values it enacts." // People internalise the way a system works and stop questioning it!!

"They are deeply imbued with particular values, prin-
ciples, norms, and ideals, and learning them is not
just about technical competency, but also socialization
into a complex organizational culture"

Some descriptive statistics:
"In the English-language Wikipedia, 22 of the 25 most active editors (by
number of edits) are bot accounts, and July 2017, they made about 20% of all edits to encyclopedia articles."
--> vgl: https://quarry.wmflabs.org/query/20703

What does it take to be a Wikipedian:
"when that partici-
pation requires not only learning Wikipedia-specific
jargon, norms, style guides, and rules, but also learning
how to interact with all the bots and power tools"

"Wikipedia demonstrates how the issues in and around
algorithmic systems are as much social as they are tech-
nical, going far beyond the opacities that arise around
proprietary source code. My argument extends Burrell’s
(2016) discussion of three different forms of opacity in
machine learning: intentional secrecy (proprietary
source code), technical literacy (such as learning to
read code), and opacities inherent in machine learning
(such as issues of interpretability). To these forms, I add
another: the opacities in learning a particular institu-
tional or organizational culture that is supported by
algorithmic systems."
// source is open, but who can actually read it? and is willing to invest the time and energy in order to hold the system accountable?
// vgl auch Gedanke von Claudia: "Wikipedia is spannend, weil wir daran das erforschen können, was wir an Facebook nicht können. Und weil die ein Abbild der Gesellschaft im Kleinen ist."
// vgl auch Web Science def: observe micro behaviours in order to study macro phenomenons (governance, ..)

Def "algorithmic": "as involving encoded proced-
ures, which are typically—but not exclusively—compu-
tationally implemented."

"Like all algorithmic systems, the ones I studied in
Wikipedia were designed, developed, and deployed by
people." //all developers are human and all humans make mistakes^^

"As Gillespie (2014) argues: ‘‘A socio-
logical analysis must not conceive of algorithms as
abstract, technical achievements, but must unpack the
warm human and institutional choices that lie behind
these cold mechanisms.’’"

Seaver (2013: 9–10) Def Algorithmic System:
"It is not the algorithm, narrowly defined, that has
sociocultural effects, but algorithmic systems — intri-
cate, dynamic arrangements of people and code. . .
When we realize that we are not talking about algo-
rithms in the technical sense, but rather algorithmic
systems of which code strictu sensu is only a part,
their defining features reverse: instead of formality,
rigidity, and consistency, we find flux, revisability,
and negotiation."
"In this context, I ask: for whom are algorithmic systems
(and the organizations that rely on them) formal, rigid,
and consistent, and for whom are they in flux, revisable,
and negotiable?" //Vorwissen, das die Menschen mitbringen, ist wichtig!

2nd level digital divide:
"who had
the knowledge, skills, and sense of empowerment to use
the Internet in ways that further engaged, empowered,
and benefitted their lives." nach Hargittai 2002

Everything's open:
"We must look at more than the fact that partici-
pation in Wikipedia is open to the public; that the infra-
structure supporting it is open sourced; and that the
community’s policies, procedures, and norms are docu-
mented in thousands and thousands of pages of text."

BUT
"We must also look at what kind of skills, knowledge, and
investment is required to fully and successfully partici-
pate,"

speaks of deletion of substandard encyclopedic articles: Where and how are the standards defined? Who defines them?

"article about a
website fails the A7 criteria in the CSD process,
which demands that articles ‘‘credibly indicate the
importance or significance of the subject.’’ (A majority
of speedy deleted articles are tagged with templates
containing A7 rationales (Geiger and Ford, 2011).)"
// ich finde dieses Kriterium ist äußerst mit Vorsicht zu genießen, da die Tür weit aufgemacht wird für Sexismus, Rassismus und andere Arten von Diskriminierung von Inhalten, die der Mehrheit von white dudes nicht passen

"Yet I had a
second, subtler motivation, hoping that in properly
demonstrating correct usage of such a template within
the established workflow of this process, I would be
made legible as a Wikipedian who knew the CSD pro-
cess and should be given some more leeway—unlike
most of the people who were creating articles that
they were deleting." //making use of the brocode^^

"Such systems do not eliminate the need for human
labor, but instead transform the kind of work that
takes place,"

erwähnt auch Abschrecken von newcommers

"As
Seaver (2013) notes with his critiques of various ‘‘crit-
ical algorithms studies’’ literature, it is easy to slip into
a mode of analysis where social factors are contextua-
lized, while infrastructure remain static and determin-
ing. Such an approach ‘‘keeps algorithms themselves
untouched, objective stones tossed about in a roily
social stream’’ (10)."

"the algorithmic
systems themselves are constructed, negotiated, contex-
tualized, and differently interpreted and enacted." // aber wer kann beim Aushandeln mitmachen?

"Wikipedia’s computational infrastructure is
also designed and governed in a relatively open
manner by the project’s volunteer community of edi-
tors (Forte and Bruckman , 2008; Gilbert and Zachry,
2015; Kennedy, 2010), unlike most of the automated
systems that are increasingly prevalent in digitally
mediated environments." //jup. und selbst da blick man nicht durch

Requirements/Expectations for bot developers:
"bot developers are generally expected to be responsive
to reasonable requests and concerns from the
community."

"Wikipedians discuss and debate
about what kinds of bots should exist in the project,"

"one of the
paradoxes of openness is that it can take substantial
time, energy, investment, and resources to fully take
advantage of all the materials released"

Veterans vs newcomers:
"they make it far easier for veteran Wikipedians to
engage in the kind of specific, complex, multifacted
work involved in the governance of Wikipedia. This
can make it far more difficult for newcomers to partici-
pate—not necessarily because bots, algorithms, or
assisted tools are inherently difficult to deal with, but
rather because bots support more complex kinds of gov-
ernance practices in Wikipedia, and complex govern-
ance practices are difficult for newcomers."

=========================================

\cite{GeiHal2017}

replicate + refute earlier results (of the paper "Even Good Bots Fight")
methods: combi: qualitative + quantitative
trace ethnography: "seek to understand data in the context it has within a community of practice," "data to be a starting point for further contextualization and interpretation,"
operationalise conflict!
distinguish conflict from non-conflict in bot reverts
compile data set + meta data
background: wikipedia researchers + long-time contributors
findings: overwhelming majority of the reverts are routine collaborative work between bots
metrics: time between reverts; number of reverts per article for the same bot pair
in addition: in depth analysis of random examples from different parts of the statistical distribution of the metrics
classify patterns in edit summaries

research question: "to what extent are bot-bot reverts
in Wikipedia genuine conflicts where disagreements about how Wikipedia ought to be written were
embedded in opposing bot codebases, versus cases like Shoreland’s Addbot that reflect the opposite?"

Out of context Addbot's edits seem like a bot ran rampart.
In context it's been tons of useful work.
Do not tear data out of context!

"The EGBF paper operationalized
bot-bot conflict through reverts, which is when one user account undoes another user account’s
edit." // Geiger+Halfaker operationalisieren den Begriff differenzierter

Literature Review: bis dato Arbeiten zu bot feedback; und criticism about driving away newcomers; aber keine Forschung hat Revert Wars thematisiert;

conflict: not necessary negative, but can be generative and stimulating (avoid filter bubbles) if resolved in a respectful manner

Conflict typology:
task conflict
process conflict
relationship conflict

Types of reverts:
identity revert: "as bringing it back to an exact previous state"
partial revert: "part of an edit is removed"
declarative revert: "when a user leaves a note in an edit summary stating that they are reverting the edit (matching “rv” or “revert”)."
-> Work based on identity reverts

"They note a single revert is not indicative
of conflict, but repeated back-and-forth reverts are indicative of an edit war"

"The “Bold, Revert, and Discuss”
cycle (one of the most widely-cited essays [31] in English Wikipedia) states that editors ought to
be bold in making changes, feel free to revert others’ changes that they find unacceptable, then
discuss the issue" // kommt mir iwie netter vor, erst zu diskutieren, dann zu löschen

Types of conflicts:
* bot-bot conflict: bots are programed with opposing directives --> not many cases found
* conflict about bots: human editors in conflict over what bots ought to be developed --> many cases found, conflict not limited to discussions about bots though, part of day-to-day work on Wikipedia
* sometimes conflict turns interpersonal

Check Geiger "Lives of bots" for history of Bot Policy;

"Unapproved bots are not allowed to edit encyclopedia
articles; they must get prior approval from the BAG for a specific, well-defined task."
"Operators of approved
bots are also obligated to respond to issues and concerns raised to them, and failure to do so can
get a bot’s approval revoked by the BAG."

Claudia's paper:
"“In both cases of algorithmic governance
– software features and bots – making rules part of the infrastructure, to a certain extent, makes
them harder to change and easier to enforce” (p. 87)"

"Dozens of language versions of Wikipedia have their own bot policy and bot ap-
proval process or group (which are generally modeled on English Wikipedia), including Japanese,
Italian, French, Romanian, Portuguese, Spanish, Japanese, and Mandarin Chinese. There is also a
much stricter global bot approval process for the smaller language versions that do not have their
own bot approval process (similarly modeled English Wikipedia),"

"when working with large-scale “found data” [36] of the traces
users leave behind when interacting on a platform, how do we best operationalize culturally-specific
concepts like conflict in a way that aligns with the particular context in which those traces were made?"

iterative mixed method
combination of:
* quantitative methods: mining big data sets/computational social science
"begin with one or
more large (but often thin) datasets generated by a software platform, which has recorded digital
traces that users leave in interacting on that platform. Such researchers then seek to mine as much
signal and significance from these found datasets as they can at scale in order to answer a research
question"
* more traditional social science/qualitative methods, e.g. interviews, observations, experiments

beware of decontextualisation! (the problem with the Even Good Bots Fight paper)
All models are wrong but some of them are useful.
"There is inevitably something left behind or incompletely captured in any transcription or
translation of an entity or event in the world [10, 42, 70]."

Star: "ethnography of infrastructure":
"discusses the “veridical” approach, in which “the information system
is taken unproblematically as a mirror of actions in the world, and often tacitly, as a complete
enough record of those actions” (p. 388).
She contrasts this with seeing the data as “a trace or record
of activities,” in which the information infrastructure “sits (often uneasily) somewhere between
research assistant to the investigator and found cultural artifact."

"At the
broadest level, this paper is about how to cook and prepare a dataset with care."

Generating data set: all edits till 2016? with all meta data.
("The dataset released by the EGBF authors only
ranges from 2001-2010, does not contain full metadata for each edit, and was generated by software
code that is not publicly available.")

Identifying bot accounts:
* bot user group (limitations: bots get frequently removed from/unflagged when they are no longer active)
* user_former_groups : former bots
* "Bot user" cross-wiki category
--> 6522 current and former bots identified across all language versions

Identify reverts with: https://github.com/mediawiki-utilities/python-mwreverts

"bot-bot reverts grew and peaked in 2013 across all languages, then have
declined since."

fast reverts: more likely to constitute a conflict
consensus can change: bots make articles comply with new policies in bulk

"we found a substantial amount of
bot-bot reverts were undoing an edit the other bot had made months, even years after."
median time to revert: 62 days; and it's been rising over time

"decreased incidents of bot-bot conflict as various language
versions gained stronger and more established bot policies and bot approval venues."

"93.2% of
bot-bot reverts were not reciprocated or other-
wise responded to by the bot that was reverted."
"our max was
two cases where the same two bots each re-
verted the other 41 times on the same article."

"What kinds of work are these bots were doing?
What were the bot’s developers intending the bots to do?"

"Trace
ethnography is not “lurker ethnography” done by someone who never interviews or participates in
a community."
trace literacy --> get to know the community; know how to participate in it

What are the traces they looked at:
- start with the revision ID of an identified bot-bot revert
- follow other traces to find other contextual information, such as:
  - what was changed in the revert,
  - the bot developer’s summary of what the bot was doing at the time,
  - the other edits that both bots had made,
  - both bots’ Requests for Approval before the Bot Approvals Group (if any),
  - the various talk pages where Wikipedians would raise and resolve the conflict (in cases of genuine conflict),
  - and the various policies and guidelines in force at the time of the revert.

"we know what does not get captured in logs and revision histories;"

thick description of different prototypical cases:
Non-conflicts:
- fixing double redirects (see paper for details):
  - task carried on by a lot of bots (code for that also provided in the pywikibot framework)
- removing interwiki links? (since linking between language version got exported to Wikidata)
- updating of article notification templates (page is protected from editing or has some issue; template removed when the issue is resolved)
- moving categories
- editing "per" justification: "single purpose bots that are written to implement a decision reached
by Wikipedians that applies to many articles in a category or even across the encyclopedia." --> may be reverted when consensus change again

Conflicts - specific cases:
- Mathbot and Frescobot over link syntax.
  - no fundamental disagreement between developers about what ought to be done
  - bots still programmed with opposing tasks
  - took over 2 years before it was noticed
- Mathbot's disambiguation links
  - conflict/disagreement between Wikipedians about: first task, then process and at the end it also turned to interpersonal for some people
- Archiving links: AnomieBot vs CyberBot II.
  - 41 revert sequence on a single page over the course of only 4 days,
  - most intensive bot-bot revert war in our dataset in terms of reverts per page per day
  - task conflict; one of the bots had a bug

classify patterns in edit summaries
(NOTE: "However, these
summaries are records of what the bot developer has programmed the bot to say the edit is doing
(as opposed to what the bot is actually doing).")
- grouping edits by reverting comment and counting the most frequently occurring comments
- counting the most commonly occurring words and n-grams in comments.

Conclusion:
"We found that the overwhelming majority of bot-bot reverts on articles are better characterized as
routine, productive, and even collaborative work between bots."
edit wars < 4% of reverts (more like 0.5%)

bot governance: similar to article governance

-What-Who is a bot? --> Bot Def!!
"for us, bots are inextricably linked to their developers, rather than autonomous agents who can
be studied independently of the people who develop and operate them. Speaking to this, many
Wikipedia bot developers name their bot not after the task it does, but after themselves: CydeBot
is run by a user named Cyde, Addbot is run by Adam Shoreland (whose username is Addshore),
CyberBot is run by a user named Cyberpower678, Xqbot is run by a user named Xqt, and more."

"the actual programming of the bot to complete a particular task is only a part of what bot developers do"
"there is also a substantial amount of social-organizational work that takes place behind the scenes"
"must speak and advocate for their bots in the Wikipedia community, which is a requirement of
the bot policy."
"Bot developers make proposals to the Bot Approvals Group, respond to issues and
concerns from BAG members and other Wikipedians before and after approval,"
"Bot developers who do not sufficiently respond to issues raised about
approved bots are liable to having their bots blocked."

assemblages:
"entirely different question to ask about the dynamics of conflict
when we see bots as assemblages of code and a human developer/advocate, who is responsible for
operating the bot in alignment with Wikipedia’s complex policy environment."

what bots should be created is an epistemological issue

data do not speak for themselves! context needed -> membership in a community of practice

English is the primary language of both authors, limited understanding of other language versions

====================================================

{IliadisRusso2016}

overview article

big data is not neutral but instead consists of already constituted assemblages

"Data are a form of power."
"lack of data is another indication of power, the power
not to look or to remain hidden (Brunton and
Nissenbaum, 2015; Flyverbom et al., 2016)."
"foreground data’s power structures"

current research trends: positivist approach (and not critical)

"Data, along with its sciences and infrastructures, are informed
by specific histories, ideologies, and philosophies that
tend to remain hidden, though there have been recent
calls for inquiry into these domains (Beer, 2016; boyd
and Crawford, 2012; Crawford et al., 2014; Floridi,
2011; Kitchin, 2014, 2015)"

"Big Data are
susceptible to losing provenance and their ability to be
‘‘about’’ only one thing, their origins and interpret-
ations becoming multiple and conflicting as metadata
are mixed with primary, secondary, and derivative
data."
-> data disorder
-> potential for harm to data subjects

Def:
"critical approach to Big Data
investigates meta-theoretical modes of conversation
and styles of scientific thinking"
"analyzes the
ground upon which positivistic Big Data science stands."
"How do Big Data inflect and interact with society,"
"CDS has emerged as a loose knit group of
frameworks, proposals, questions, and mani-
festos"
"What need to be established are long-term projects"

data assemblages:
"CDS should study ‘‘data assemblages,’’ that is ‘‘the
technological, political, social and economic appara-
tuses and elements that constitutes and frames the
generation, circulation and deployment of data’’ (1)." (Kitchin, Lauriault 2014)
"The
apparatus and elements of a data assemblage may
include systems of thought, forms of knowledge,
finance, political economy, governmentalities and leg-
alities, materialities and infrastructures, practices,
organizations and institutions, subjectivities and com-
munities, places, and the marketplace where data are
constituted."
"Data assemblages are the powerful complex of entities
that form the underlying production of Big Data sci-
ence at multiple levels of abstraction and in a plurality
of domains."

"CDS follows three basic principles derived from this
broadly Aristotelean approach: the identification of
social data problems, the design of critical frameworks
for addressing social data problems, and the applica-
tion of social solutions to increase data literacy."

=================================================

\cite{GeiRib2011}

- Define/Present the methodology of trace ethnography
- Illustrate it using the case study of tracing/banning vandals on wikipedia


Def
"combines the richness of participant-observation
with the wealth of data in logs so as to reconstruct
patterns and practices of users in distributed
sociotechnical systems."

"integrates and extends
a number of longstanding techniques across the social
and computational sciences"

"exploits the proliferation of
documents and documentary traces"

"traces not only
document events but are also used by participants
themselves to coordinate and render accountable many
activities"

"heterogeneous data – which include transaction logs,
version histories, institutional records, conversation
transcripts, and source code"
"allowing us to retroactively reconstruct specific actions
at a fine level of granularity"

"sets of
such documentary traces can then be assembled into
rich narratives of interaction"

"turn thin documentary traces into
“thick descriptions” [10] of actors and events"

extends/assembles various existing methods to counteract the common concern with the limitations of traditional single-sited participant observation

"explicitly or implicitly,
documentary traces are the primary mechanism in
which users themselves know their distributed
communities and act within them."

"traces can only
be fully inverted through an ethnographic
understanding of the activities, people, systems, and
technologies which contribute to their production."

traditional ethnographic observation is costly and inpractical in distributed settings (and may miss phenomena that occur between sites)

Strategies for studying distributed systems:
- study documentary practices
"trails of correspondence
between scientists [24,26], the manuals and handbooks
that seek to harmonize practice within corporate
organizations [22], trading records in global financial
markets[15], or the standards and protocols that guide
technology development and use [5]"
"often the case even in
traditional co-located organizations."

following workers around (traditional ethnographic observation) -> following documents around
"following these documents as they travel
across the site, asking how, where, and by whom they
are produced, edited, revised or filed"
"By focusing
on the lifecycles of these documents, the researcher is
able to follow workflows of activity across an
organization"

- participant-generated ethnography
"having participants capture their own qualitative data"
user-authored diaries or journals
plus: "balance the need for rich,
thick, and highly-empirical data with the practical
limitations involved with performing ethnographic
fieldwork,"
minus: "on its
own, it lacks the same holistic understanding gained
though ethnographic observation."
"there may be entire swaths
of activity that are left of these logs (whether because
they are embarrassing for recorders, or simply
considered too mundane to be worth mentioning)."

- historical and archival ethnography (vgl Challenger Bsp)

- Multi-Sited Ethnography (‘Follow the Actors’)
"especially around topics like
globalization, migration, nationalism, and other issues
that are not typically present in a single site."
"researcher travels to multiple sites"
NOTE: "visiting multiple
sites is intended not to give the ethnographer more
cases, (i.e. for a broader or more representative
sample), but to expand a single case beyond its
immediate location."
ANT: follow the actors (mobile populations, materials, stories, ideologies, metaphors, conflicts)

- Strategically-situated ethnography
be at the right place at the right time
"Instead of
trying 'to be everywhere' in a large network
[...]
deliberately situated themselves at the particular times
and places where a system is being designed,
constructed, contested, broken, or repaired [25]."
"identify the most relevant, important, or
representative local sites in a distributed organization,"

"In studies of science, focusing on a moment of
controversy can be particularly revealing, as expert
participants pick apart each others’ evidence and
arguments [7]."

"most heavily relying logs
and records that are automatically generated in digital
environments"
--> especially in software platforms for the production and distribution of content, zB:
"blogs, wikis, source code repositories,
content management systems (CMS),"

"who changed what to a
document and when, so that an author can
reconstruct the history of a document"

Understanding codes!
"Embedded within these
archival records of who changed what and when, we
found a wide variety of codes that we initially passed
over, seeing them as either incomprehensible markup
or relatively non-descriptive"
"Like all codes, they are
sociotechnical, and therefore their meaning can only be
understood in relation to their broader cultural and
computational systems"

Critique:
"it only can observe what the system
or platform records, which are always incomplete."

Case study: tracing vandals in Wikipedia
Inverting the traces:
- collect MediaWiki revision data (for a single user)
- analyse edit-summary fields (used sparsely by humans, but extensively by bots and tools in a regular fashion)
- pay special attention to markers (codes): observe users that leave them, try to understand when are they used
- look around for documentation
- try out the semi-automatic software tools for themselves to get a understanding of what tasks they perform and what traces are generated along the way (these tools generally prescript narrow paths of action)

"Becoming familiar with traces requires both
immersion in the average, everyday affairs of a group
and active investigation of otherwise backgrounded
actors, software, and data."

the tools (Huggle and Twinkle) issue warnings with automatically decided warning level

1) initial ethnographic fieldwork: identify routines
2) locate/aggregate via documentary analysis
3) assemble a chain of activity

bsp of Wikipedians inverting the traces themselves for a disciplinary hearing about a conflict between admins

Limitations:
"the methodology described does
not tell us how the organizational routine of four
escalating warning was originally developed and
implemented, or the attitudes vandal fighters hold
towards it."

Concerns:
- ethical: breaching privacy via thickening the traces; no possibility for informed consent

====================================================================

\inproceedings{ButJoyPi2008}

wikis allow for a wide range of structures

aim of the paper: "to propose and apply a conceptual framework for
understanding the natures and roles of policies in wikis"

"one of the founding principles of
Wikipedia is “Ignore all rules,” which states that if a rule
inhibits developing Wikipedia, the contributor should
ignore it [45]."

Stand Sept. 2007 (EN Wikipedia) TODO: vgl mit heute
* 44 pages in the "Wikipedia Official Policy" category
* 248 in "Wikipedia Guidelines"
* 45 pending proposals for guidelines and polcies
* 200 rejected proposals for guidelines and policies

study concentrates on formal (written) norms
* easier to study, because explcit
* versions, discussions on them a written
* serve as boundary objects
* often sites of conflict (because are explicit and visible)

use rules/policies/guidelines interchangeably
vgl Wikipedia def:
"“A guideline is any page that is: (1) actionable (i.e. it
recommends, or recommends against, an action to be taken
by editors) and (2) authorized by consensus. Guidelines are
not set in stone and should be treated with common sense
and the occasional exception.
A policy is similar to a guideline, only more official and
less likely to have exceptions.” [48]"

aufbau: walk through different purposes/wahrnehmungen of rules and policies
(drawn from prior work) and illustrating how each of them applies to Wikipedia
1. Rules and Policies as Rational Efforts to Organize or Coordinate
2. Rules and Policies as Evolving, Competing, Self-propagating Entities
3. Rules and Policies as Constructions of Meaning and Identity
4. Rules and Policies as External Signals
5. Rules and Policies as Internal Signals
6. Rules and Policies as Negotiated Settlements and Trophies
7. Rules and Policies as Control Mechanisms

1.)
"All groups are faced with challenges created by
communication and coordination problems"

Def Rules:
"rules are conscious, intentional
actions put in place for the purpose of improving collective
performance."

"assume that all parties have the same motivations and goals"

"important in contexts
where there is high turnover (people coming and going on a
regular basis), where there is substantial autonomy of
action, and where explicit coordination is costly"

=in Wikipedia=
* high turnover
* editors distributed globally
* coordination necessary
* policies and guidelines to achieve reliability and consistency
* policies and guidelines confirm the authority of the administrators
* administrators: the authority most likely to implement the policies
* witten polcies and guidelines needed to facilitate and transfer knowledge
* fewer policies specified for administrators than users
* administrators change not as frequent as users
* written policies ensure coordination and prevent arbitrary decisions
* no need for lengthy discussions and consensus seeking for each decision

2.)
check ich nicht ganz^^, paar zitate:
"This perspective
rejects the idea of intention, design, and agency as the
primary drivers of policy development, largely because of
the bounded rationality of individuals and high levels of
complexity in the organizational system."

"rules are the result of competition for shifting
attention"

"rules generate more rules"

=in Wikipedia=
"For Wikipedia, the basic conditions of this perspective
definitely apply."
"extremely complex system
of documents, people, roles, policies and guidelines, yet
individuals possess bounded rationality"
"All policies studied grew enormously."

"attempts to take the complex system that is Wikipedia and
make it manageable"
"promotes the continuous updating and modification of
rules"

3.) Rules and Policies as Constructions of Meaning and
Identity

"answer questions about “who we are”"
"indicate the way things “should be” (i.e.,ideals)"
"Rules in this role allow the wiki and its users to develop a
sense of identity and meaning"

=in Wikipedia=
* define what Wikipedia is and is not (explicitely or through policy pages on
  community principles, such as Ignore All the Rules)
* identity construction reflected in discussions of policy changes, whether or
  not smth is consistent with the "core principles" (example: discussion around
  the Neutral Point of View Policy)
* Wikipedia is NOT
  * printed and published encyclopedia written by paid experts
  * a bureaucracy :P
* disagreement should be resolved through a consensus based discussion
* lays out explicitely norms for community behaviour
* "Follow the spirit, not the letter, of
any rules, policies and guidelines if you feel they conflict."

4.) Rules and Policies as External Signals
"Sometimes rules are ways of indicating to outside
stakeholders or concerned parties that things that they care
about are being attended to."

=in Wikipedia=
* Bsp: Copyrights policy
"it appears they were developed in
response to external complaints or concerns about the
unpermitted use of protected material [47]"
"The language evolved from simple sentence
structures and vernacular style into the more complicated
grammars and dictions of the legal profession, possibly due
to the hiring of general counsel"
"pressures to protect itself and its reputation from outside
attacks or influences."

* another example: Biographies of living persons policy
"It includes full contact information for Jimmy Wales as
the “Designated Agent” (which references specific
requirement of US Law)"
"explicitly references external legal structures
requirements"
"very insistent language"
"In internal discussions, explanations for the policy and
changes to the policy are described in the third person"
"external attention triggers changes"
"The policy is referenced in statements to external
stakeholders and media."

"demonstrating that the
wiki and its members recognize an issue as important or
significant."

"rules which
act as external signals speak to external audiences and are
not necessarily meant for internal audiences, or members."

5.) Rules and Policies as Internal Signals
"signal to the community
what the community finds important,"

=in Wikipedia=
* bsp Civility Policy (promote polite interactions between members)
* "Policies fitting into this category are not
threatened by outside forces, so their language can remain
less formal"

"triggered by either internal members (e.g. via complaints or
problematic events) or external viewers."

6.) Rules and Policies as Negotiated Settlements and
Trophies

"People have different interests or perspectives"
"Settlements
are creating to avoid the cost of continued conflict, while
trophies are created to give credibility and influence to the
“winner” in future discussions."

=in Wikipedia=
* references to that which "has already been decided"
* bsp Consensus Policy (lenghty description, people referring to smth 
  previously decided)
* prevents continuous recycling of old fights and unresolved contentions

"The
question then arises is how large must the majority be to
ignore the opinions of a minority?”"

7.) Rules and Policies as Control Mechanisms
"Control is
defined as any effort made to ensure appropriate action"

"attempts to ensure that individuals on a project team act in
accordance with a previously agreed-upon strategy to
accomplish desired goals and objectives"

"formal modes control via performance
evaluation and rewards while informal modes control via
socialization to reduce goal differences"

"rules are used to
manage divergence of individual and organizational goals"

=in Wikipedia=
* hierarchy of roles: the administrator class applies control mechanisms for
  the group
* sometimes claimed this hierarchy doesn't exist
* sometimes individuals have distructive goals (i.e. vandalism)
* in such cases policies like Blocking prevent chronic disrupters from damaging
  group efforts
* policies "encourage" appropriate behaviour
* Three-Revert Rule (No more than 3 changes to a page within 24h) to prevent
  edit wars

Conclusions
"pursuing the “policyless” ideal
that wikis represent is a pipedream. Policy creation and
maintenance is an important aspect of the work that must be
done to keep the community running"

* there are pitfalls, if policies and regulation mechanisms are directly
  embedded into the software
"Since policies can also be highly
symbolic or meaning-filled, embedding them or automating
them may not work because it could remove this function or
make it less effective for this purpose."

==================================================

\cite{MueDoHer2013}

speak of "encoded rules"

2 categories of governance mechanisms: social and algorthmic
* social: based primarily on communication; social norms are often formalized by
written rules and guidelines
* algorithmic: "techical infrastructure that enables users to access artifacts"
"That allows
the community to communicate and coordinate their collective ac-
tions to create those artifacts."

Research question: "how a community’s
consensus gradually converts social mechanisms into algorithmic
mechanisms."

Analyse algorithmic governance mechanisms for "flagged revisions" and "xqbot"

Aims of the paper:
"(1) characterizing social and algorithmic governance
mechanisms,
(2) discussing implementations of algorithmic gover-
nance mechanisms,
(3) presenting examples of how existing
social mechanisms are successively manifested in the technical in-
frastructure by converting them into algorithmic mechanisms."

"the community gradually transfers “rights to rule” to bots"

Governance def: "From a strategic management perspective, Williamson defines
gov-
ernance as the creation of order to achieve mutual gains in poten-
tially conflict-laden contexts [39]"
"A carefully negotiated and balanced set of rules
is required to ensure the long-term survival of such commons-based
governance regimes [22]."

participation in FLOSS projects highly dependent on the governance structures

governance regime -> dynamic phenomenon
"community’s perception of its governance regime
may change over time [16]."
"communities are likely
to introduce bureaucratic mechanisms into a stabilized governance
regime, which would have been unthinkable in earlier phases"
"On an individual level, [...] artifacts [...] are important in terms of their role as
a coordination mechanism"

Components of a governance regime:
(1) structures and processes, (2)
informal, formal, and encoded rules, (3) externally applied as well
as internalized rules, and (4) mechanisms of both trust and verifi-
cation/control” [18].

Different views on governance in Wikipedia (check also Schoeder and Wagner[24])
* comparably egalitarian and participatory governance
* bureaucratic features
* "strict hierarchical content management system"

changed substantially over time

Bot DEF!
"Bots are “fully-
automated software agents that perform algorithmically-defined tasks
involved with editing, maintenance, and administration” [9]. How-
ever, bots are not exclusively interpreted as software tools but also
as managerial protocols [20] that are part of the infrastructure [8]"

"It is argued that the majority of bots are not authors but that all bots
can be seen as “content agents” [20]."

Bot taxonomy: (vgl. Halfaker et al. [12]):
"(1) bots that transfer data from pub-
lic databases (e.g., census data) into articles,
(2) bots that monitor and curate articles,
(3) bots that extend the existing software func-
tionality of Wikipedia’s underlying MediaWiki software (e.g., by
converting an ordinary page into a dynamic, priority-based discus-
sion queue), and
(4) bots that protect against malicious activities."
//Wo kommt hier die Community-Unterstützung rein? (E.g. Bots, die neue User
//grüßen oder diejenigen die Beiträge auf Talk-Pages unterzeichnen?)

"Bots’ activities are often hidden from human editors [7] because
their edits are automatically filtered from the article history log."
//TODO: ist das immer noch so? Ich glaube tatsächlich nicht; Following entries found in the article's history https://en.wikipedia.org/w/index.php?title=Jamaica_Kincaid&action=history
(cur | prev) 06:49, 27 July 2018‎ Josvebot (talk | contribs)‎ m . . (29,346 bytes) 0‎ . . (Fixing WP:CHECKWIKI #16: unicode contol character (and other minor general edits caused by AWB), replaced: →) (undo)
(cur | prev) 17:16, 9 July 2018‎ Bender the Bot (talk | contribs)‎ m . . (29,346 bytes) +1‎ . . (→‎Early life: HTTP to HTTPS for Mother Jones, replaced: http://www.motherjones.com/ → https://www.motherjones.com/ using AWB) (undo)
(cur | prev) 09:22, 19 June 2018‎ KolbertBot (talk | contribs)‎ m . . (29,345 bytes) +4‎ . . (Bot: HTTP→HTTPS (v485)) (undo)

"Geiger and Ribes claim that
the redistribution of work between human and non-human contrib-
utors also transforms the “moral order” of Wikipedia because the
assessment of human edits is carried out mainly by automated or
semi-automated tools [9]."

"In Wikipedia, bots are described as programs or scripts that help
their operators to carry out “mindless, boring and often reoccurring
tasks” (e.g., typo corrections). Similarly to human users, bots have
their own user pages that contain amongst other things the name of
the operator, a description of their tasks, and a link for administra-
tors to shut them down if needed"

"bots have no edit limits, they are allowed to work on semi-protected
pages" //normal users have edit limits?
"speed reduction of maximal five edits per minute"

Requirements for a bot flag:
* user name should contain the word “bot”,
* a specific bot template has to be included on the user page,
* the bot should provide some successfully carried out sample edits,
* and the application for a bot flag has to be announced to the community.
* Additionally, bots should only operate in the main namespace (that contains
  all articles)
und trotzdem: "in 2012, these “outside” edits accounted for over 40 percent of
all bot edits."
"In 2001, about 90 percent of all edits were carried
out in the article namespace, but in 2006, this number had already
decreased to 70 percent [15]."
* Exceptions are possible, but these have to be discussed with and agreed
  to by the community.


Social governance mechanisms
* based on social information
* "Contributors need social information to define
their role in a peer production community as well as to under-
stand existing norms, policies, and procedures that are needed to
carry out tasks"
* "mechanisms that support communication in terms of an informal
organizational structure"
* "mechanisms that relate to the formally
defined organizational structure."

Algorithmic governance mechanisms
* "OOS research focuses on technical artifacts such
as standards, architectural documentation, and the API descriptions"
* "Wikipedia context is mostly related to bots"

Ideosyncracies of both:
* "algorithmic mechanisms scale up well but
social mechanisms do not."
* "social mechanisms
handle exceptions better than technical mechanisms"
* "algorithmic mechanisms ensure that arbi-
trary behavior can be reduced, for example in terms of this handling
of exceptions."

compare results of findings about the EN Wikipedia with the DE wikipedia

"overall development of the
German version of Wikipedia follows a similar impressive pattern
to its larger sister project, we found substantial differences with re-
gard to the implementation of algorithmic governance mechanisms,"

Findings:
"we show how bots, al-
gorithmic tools originally implemented to support content creation,
are being used increasingly for governance purposes."
//kommt es aus den Daten hervor, dass Bots früher eher für Content creation
//genutzt wurden? Oder woher weiß man das?

"Policies “that
all users should normally follow” as well as guidelines that “outline
best practices for following those standards in specific contexts”
are not considered to be “hard-and-fast rules”" //vgl auch the Bureaucracy paper

"The notion of Wikipedia as a democracy is rejected explicitly"
but it offers democratic tools used for decision-making (e.g surveys and polls)
"“most decisions on Wiki-
pedia are based on consensus, not on vote-counting or majority
rule”.[38]"
"majority of votes is not generally
considered enough to legitimize decisions"

1st major difference EN/DE Wikipedia:
- automated vandal fighting not permitted in DE Wikipedia (ist es immer noch
  so?)
"algorithmic tools are only intended to support editors in identify-
ing possible malicious edits, but automated assessments are not
accepted"
"Fighting vandals is seen as a form of handling excep-
tions and should therefore be based upon human evaluation."

2nd difference (Stand Dec 2012):
- Flagged revisions in DE Wikipedia, but not in EN ("where the “Pending
Changes” tool was introduced after lengthy discussions")
"Whereas access to this governance feature is restricted socially on
the English Wikipedia, the German language version grants this
particular right automatically."

"The whole system now works mostly automatically, which is why
many if not most editors receive reviewer status without having to
know anything about the concept of sighted revisions. As a result,
access to the flagged revision feature scales up better than systems
of manually assigning roles such as the rollbacker user right in En-
glish Wikipedia."

"the flagged revision case
shows both the limitations of converting social into algorithmic
governance mechanisms and the potentials in terms of scalability"

descriptions of how software changes are accepted to the MediaWiki core

(January 2012):
* 72 additional extensions integrated into the German Wikipedia;
* 83 extensions in the English Wikipedia

Code is law:
"In a way, software features represent the “hard law” of Wikipedia
[17]. While policies and guidelines may be ignored"
"it is much more difficult if not impossible to
ignore rules implemented in the form of software functions."
"In both cases of algorithmic governance - software features and
bots - making rules part of the infrastructure, to a certain extent,
makes them harder to change and easier to enforce."
"The conversion of
socially developed rules into source code makes norms even less
transparent because only a small group of users can read source
code [26]."
"Additionally, users take bot edits for granted, and they
do not question them, which is reflected in their absence from the
article edit log (in the normal mode)."
// das ist doch anders rum: niemand hinterfragt sie, weil sie niemand sieht.

"Criteria that define which user can access a feature are again pro-
vided by community consensus. As a result, governance via soft-
ware features might also be subject to substantial change over time."

Stats Bot edits Dec 2012:
* DE Wikipedia: 353 users with a bot flag assigned.
* bots have been responsible for 12,183,766 edits (mean=35,410, std. dev=93,502.02) in the last 9 years.
* corresponds to the number of edits carried out by the most active
human users in December 2012 (13,747,466 edits, mean=38,945,
std. dev=48,089.02)

"Edits carried out by bots are continuously increasing in number"

"We collected task descriptions from bots’ user pages to examine
the kinds of activities in which bots are participating in the Wiki-
pedia community"
"In single, doubtful cases we matched edits with
their task descriptions to identify discrepancies"

Manual clustering of activities, 3 foci:
(1) the content focus,
    - mainly active in the article namespace
    - support the curating activities of their operators
    - connect different language versions of a page (I think this is obsolete
      since this task is now done via Wikidata?)
(2) the task focus,
    - support maintenance work
    - compile working lists
    - inform editors about existing status changes
(3) the community focus.
    - unrelated to articles
    - related to community rules and their enforcement

in detail discussion of the xqbot:
  * xqbot: initially: request speedy deletion of orphaned pages/remains of moved pages;
    2 months later: "correcting double redirects, fixing
    links on disambiguation pages, adding missing references tags in
    articles, and the setting of interwiki-links."
"The xqbot translates community consensus into practice, initially
for one selected case, but later this practice was transferred into
    similar areas without requesting additional community consensus.
    The ability of algorithmic governance mechanisms to be replicated
    easily in various areas of application has led to their increased and
    almost unnoticed enforcement of rules."

limitations:
- DE wikipedia only
- only users with the assigned bot flag
- use a manual coding scheme for task clustering, unsuitable for analysis
  reproduction?

Fazit: "growing importance of comparably rigorous algorithmic mecha-
nisms of governance in Wikipedia is at odds with the rule-skepticism
predominant among community members"
"with the growing im-
portance of algorithmic governance there is also a growing need
to govern algorithmic mechanisms."

========================================================

\cite{Star1999}

Infrastructure is boring.
"It takes some digging to unearth the dramas inherent
in system design creating, to restore narrative"

bsp reading between the lines: phonebooks
narrow phone book --> rural area
only husbands names listed for married couples -- heterosexual bias
"In the Santa Cruz, California, phone book, Alcoholics Anonymous and Narcotics
Anonymous are listed in emergency services; years ago they would have been
listed under “rehabilitation” if at all.
[...] Under the community
events section in the beginning, next to the Garlic Festival and the
celebration of the anniversary of the city’s founding, the Gay and Lesbian Pride Parade is
listed as an annual event. Behind this simple telephone book listing lies decades of
activism and conflict"

Don't neglect the infrastructure:
"Study a city and neglect its sewers and
power supplies (as many have), and you miss essential aspects of distributional
justice and planning power (Latour & Hermant, 1998)"

infrastructure is a relational concept:
"One person’s infrastructure is another’s topic, or difficulty."
"For a railroad engineer, the rails are not infrastructure but topic."

properties of infrastructure:
- embeddedness: "sunk into and inside of other structures,
social arrangements, and technologies"
- transparency: "transparent to use, in the sense that it does not
have to be reinvented each time or assembled for each task"
- reach or scope: "may be either spatial or temporal—infrastructure has
reach beyond a single event or one-site practice"
- learned as a part of membership: "The taken-for-grantedness of artifacts and
organizational arrangements is a sine qua non of membership in a community of
practice (Bowker & Star, in press; Lave & Wenger, 1991). Strangers and outsid-
ers encounter infrastructure as a target object to be learned about."
- links with conventions of practice: "Infrastructure both shapes and is shaped
by the conventions of a community of practice (e.g., the ways that cycles of
day-night work are affected by and affect electrical power rates and needs).
Generations of typists have learned the QWERTY keyboard"
- embodiment of standards: "Modified by scope and often by conflicting con-
ventions, infrastructure takes on transparency by plugging into other
infrastructures and tools in a standardized fashion"
- build on an installed base: backward compatibility; "Optical fibers run along
  old railroad lines"
- becomes visible upon breakdown: "Even when there are back-up mechanisms
or procedures, their existence further highlights the now-visible
infrastructure"
- is fixed in modular increments, not all at one or globally
  "Changes take time and negotiation,"
  "Nobody is really in charge of infrastructure."

"Sites to examine then include decisions about encoding and
standardizing, tinkering and tailoring activities"

What to study: "combination of historical and literary analysis, traditional
tools like interviews and observations, systems analysis, and usability studies."

"people make meanings based on their circumstances,"

infrastructure: scalability?
"we have the promise of a
complete transcript of interactions, almost ready-made “fieldnotes” in the form
of transaction logs and archives of e-mail discussions. At the same time,
reduc-
ing this volume of material to something both manageable and analytically
interesting is a tough nut to crack,"

ethnography acknowledges silenced voices

master narrative of systems: //vgl auch Donna Haraway
"Many information systems employ what literary theorists would call a master
narrative, or a single voice that does not problematize diversity. This voice
speaks unconsciously from the presumed center of things."
"identifying first with that which has been made other, or unnamed."

Literary devices for master narratives:
- passive voice
- personification
- generalisation

"With any form of work, there are always people whose work goes unnoticed
or is not formally recognized (cleaners, janitors, maids, and often parents,
for
    instance). Where the object of systems design is to support all work,
    leaving out
    what are locally perceived as “nonpeople”"

different levels of reference of the information infrastructure, not mutually
exclusive; can be read
as:
- material artifact
- trace or record of activities
- veridical representation of the world

artifacts have policy! bridges example

===================================================================

\cite{BarHooZie2013}

Provocative questions zum Nachdenken:
"What exactly are algorithms “doing,” and what are the implications?
Can an algorithm “do” anything?"

"aim to trouble the
coherence of the algorithm as an analytic category"

"Tarleton Gillespie identifies six dimensions of what he
termed “public relevance algorithms”:
“patterns of inclusion,” // how about patterns of exclusion?
“cycles of anticipation,”
“the evaluation of relevance,” 
“the promise of algorithmic objectivity,”
“entanglement with practice,”
and “the production of calculated publics” (Gillespie forthcoming)."

the specificity question:
algorithm = computer = software = machine = god?

"Ian Bogost has asked us to imagine what it would mean to acknowledge that “the
perception
and experience of other beings [including computers] remains outside our grasp
[...]
we
concede that the algorithms’ logic may not be available to us—not because it’s
concealed, but
because it’s entirely beyond our view"
// but is a computer "a being"?

Different ways of studying alorithms?
the technical / sociological / legal / philosophical approach

distinction algorithms/data:
"This upends the common notion that access to the source code of
software grants full access to the software’s functionality."

can every problem be addressed algorithmically?
"What might we learn from research that instead focused on poorly formed
questions and failed
implementations—problems and projects that don’t go anywhere?"

"A good example of the challenges of thinking about algorithms in terms of
problems and
solutions is the field of data mining."

"We seem to have pivoted from a discourse of overload to a discourse of
opportunity."

delegating knowledge production to machines: met with fierce resistance

2 types of automation tasks delegated to machines
- subjecting data to analysis, tasks impossible to perform manually
- decision making

agency and control: who's the arbiter? who excercises control/autority over the
algorithm?

deferral of accountability:
"Similar to invocations of
“technical failure,” responsibility and blame tend to be put on “the
algorithm”."

people are often unaware of where algorithms are at work (siehe zb Writing up
paper where a Wikipedia editor wasn't sure whether it was a bot or a person who
was deleting their contributions)
Who understands the algorithms:
"But even if these algorithms
were somehow more manifest, would we find that they are nonetheless
inscrutable?"
secrecy: trade secret, blabla
legal issues

"Is there such a thing as algorithmic neutrality or impartiality?"
"What values animate the urge for such neutrality? Fairness? Justice?"
"Yet how does one ascertain whether an algorithm is “good” or “bad,”
“fair” or “unfair,” “just” or “unjust”? Good for whom? Fair to what end? Just
according to whom? Who—or what—decides?"

bias
morality
"Will we lose control of our own morality by relying on algorithms?"
"Might algorithms have their own morality?" //vgl the trolley problem

precedence, forever burdened by history

"What would it mean to study
algorithms in practice (as Wieder studied rules in practice), and not just in
theory?"

"What ill effects might regulation itself cause? Given the
ubiquity of algorithms, do they, in a sense, regulate us?"

===================================================================
\cite{Haraway1988}

- situated knowledges instead of the omniknowing view
- objectivity from a partial perspective
- and not the unmarked privileged perspective
- the field of science as an arena for claiming power
- find a way beyond showing bias in science; no reduction to bias vs
  objectivity
- need to partially translate knowledged between different communities
- vision as a metaphor, vision enhancements
- objectivity as embodiement of all vision
- embodied vision, embodied objectivity
- learning to see faithfully from another's point of view
- unlocatable, and so, irresponsible knowledge claims cannot be called into account
- how to see from below?

"traditionally what can count as knowledge is
policed by philosophers codifying cognitive canon law"

"no insider's perspective is privileged, because all draw-
ings of inside-outside boundaries in knowledge are theorized as
power moves, not moves toward truth."
"They tell
parables about objectivity and scientific method to students in the
first years of their initiation, but no practitioner of the high scien-
tific arts would be caught dead acting on the textbook versions."
"official ideologies about ob-
jectivity and scientific method are particularly bad guides to how
scientific knowledge is actually made"

"social constructionists might maintain that the
ideological doctrine of scientific method and all the philosophical
verbiage about epistemology were cooked up to distract our atten-
tion from getting to know the world effectively by practicing the
sciences."
"science -the real game in town -
is rhetoric, a series of efforts to persuade relevant social actors that
one's manufactured knowledge is a route to a desired form of very
objective power."

"Science has been about a search for
translation, convertibility, mobility of meanings, and universality-
which I call reductionism only when one language (guess whose?)
must be enforced as the standard for all the translations and con-
versions."

"leap out of the marked
body and into a conquering gaze from nowhere. This is the gaze
that mythically inscribes all the marked bodies"
"the un-
marked category claim the power to see and not be seen, to repre-
sent while escaping representation"
"This gaze signifies the un-
marked positions of Man and White, one of the many nasty tones
of the word "objectivity"
to feminist ears in scientific and tech-
nological, late-industrial, militarized, racist, and male-dominant
societies,"

"Feminist objectivity is
about limited location and situated knowledge"

"building on translations and specific ways of seeing"

"feminism attempt to theorize grounds for
trusting especially the vantage points of the subjugated; there is
good reason to believe vision is better from below the brilliant
space platforms of the powerful"

"serious danger of romanticizing and/or appropriating the vision of
the less powerful while claiming to see from their positions"
"The positionings of the subjugated are not ex-
empt from critical reexamination, decoding, deconstruction, and
interpretation"
subjugated positions:
"least likely to allow denial of the
critical and interpretive core of all knowledge. They are knowl-
edgeable of modes of denial through repression, forgetting, and
disappearing acts"

"The alternative to relativism is partial, locatable, critical knowl-
edges sustaining the possibility of webs of connections called
solidarity in politics and shared conversations in epistemology."
"Relativism is a way of being nowhere while claiming to be every-
where equally"

god tricks: relativism and totalization

//Haraway's envisioned objectivity:
"I want to argue for a doctrine and
practice of objectivity that privileges contestation, deconstruction,
passionate construction, webbed connections, and hope for trans-
formation of systems of knowledge and ways of seeing."
// not only deconstruction but also construction!

"Science has been utopian and visionary from the start;
that is one reason "we" need it."

"Identity, including self-identity, does not produce science;
critical positioning does, that is, objectivity."

"Positioning is, therefore, the key practice in grounding knowl-
edge organized around the imagery of vision, and much Western
scientific and philosophic discourse is organized in this way."

"social and scientific
revolutions have not always been liberatory, even if they have
always been visionary"

". The metaphor invites
us to investigate the varied apparatuses of visual production"

"Translation is always interpretive, critical, and partial."

"Situated knowledges are about communities,
not about isolated individuals. The only way to find a larger vision
is to be somewhere in particular. The science question in femi-
nism is about objectivity as positioned rationality. Its images are
not the products of escape and transcendence of limits (the view
from above) but the joining of partial views and halting voices into
a collective subject position"
"views from somewhere"

capitalist colonialism
"resourcing"
"White Capitalist Patriarchy"
nature is only theraw material of culture

"Situated knowledges require that
the object of knowledge be pictured as an actor and agent, not as a
screen or a ground or a resource"
"The point is paradigmatically
clear in critical approaches to the social and human sciences,
where the agency of people studied"
"The world
is not raw material for humanization"
"Ecofeminists have perhaps been most insis-
tent on some version of the world as active subject, not as resource
to be mapped and appropriated in bourgeois, Marxist, or mas-
culinist projects"

"Femi-
nist objectivity makes room for surprises and ironies at the heart
of all knowledge production; we are not in charge of the world.
We just live here"

"I am arguing for the view from the body [...] vs the view from above, from nowhere"

===================================================================
\cite{HalKitRied2011}

purpose of reverts:
"fix mistakes, repair vandalism, and help enforce
policy."

effect of reverts on newcomers and more experienced editors;
demotivate editors; reduce contributions vs higher quality edits
effect of reverts according to tenure of the reverting editors;
    reverts by anonymous editors not very impactful
    reverts by more experienced users deminish contributions significantly
"Essentially,
editors reverted by anonymous editors recover to the same
average level of activity within a couple of weeks, but those
reverted by named editors do not recover for at least one
month (if ever)."
"we suspected that the long-
term effect on reverted editors could have been due to edi-
tors being demotivated enough to leave Wikipedia entirely."

contribution: "ours is the first study we are aware of to quantify the
impact of reverts on editor behavior."
Findings in a nutshell:
"(1) reverts do have a negative
impact on editor contribution and survival, especially for
newcomers; and (2) when editors do continue to contribute
after a revert, the quality of their contributions increases."

What can findings be used for:
"design of intelligent tools for supporting reverts that enhance
their beneficial effects while minimizing costs."

4 Research questions:
RQ1: How does being reverted affect the quantity
of editor work?
RQ2: How does being reverted affect the quality of
editor work?
RQ3: How does being reverted affect communica-
tion?
RQ4: How does experience moderate the effects of
reverts on contribution?

editing is easy for everyone: also for malicious/biased users
so reverting is also easy -> reduces cost for fixing damage

total percentage of reverts has increased over time

"tasks that may pro-
duce high group value can increase individual motivation;"
"Getting reverted may make individuals feel that their con-
tributions are not valued by the group and are not leading to
positive group outcomes, resulting in demotivating effects."

"being reverted could be part of the learning
process for editors."

Wikipedia’s Bold, Revert, Discuss cycle

more policies and guidelines -> newcomers are reverted at higher rates

Data sample: 400 000 revisions; January 2010 data dump
200 000 samples of not reverted revisions used as a control group
no two revisions performed by the same editor

Quantity measures:
Revisions/day
Words added/day: number of non-stop words added to articles per day

Quality measures:
Reverts/revision: "the proportion of an editor’s revisions
that have been reverted in a given timespan."
PWR/word: "the average number
of revisions that words added by an editor persist. Higher
quality contributions should, on average, last longer."

Boldness measures:
Words changed per revision
Establishment of words removed: the average PWR of
words that an edit removes
users may appear to make higher quality contributions by making "safer" edits

Productivity measures:
combines quality and quantity to estimate impact
PWR/day:

all these measures focused on articles; don't consider improvements on policy pages, etc;

Measuring communication:
- about articles: article talk page -> Article Talk revisions/day
- personal communication between editors: user talk page -> User Talk revisions/day

"editors who are reverted are less likely
to get reverted in the future."

"After a revert, old-timer editors do experience a tempo-
rary reduction to their article activity, but they return to the
level of activity of their not-reverted counterparts within two
weeks of being reverted. For newbie editors, the difference
in the activity delta is both stronger and longer-lasting. Re-
verted newbies take more than four weeks to return to the
activity levels of not-reverted newbies."

but less experienced editors learn more from reverts and have bigger improvements in their article quality

"activity
of editors reverted by newbies will recover within two weeks,
the activity of editors reverted by old-timers did not recover
in the four observed weeks."

"Another interpretation is that old-timers
have an enhanced ability to identify unconstructive editors
and chase them away" // wistful thinking

interestingly:
"Under our measure of pro-
ductivity (PWR/day), the net effect of reverts on Wikipedia
is positive: on average, an editor who is reverted produces
more persistent words per day – even if we include those
editors who withdraw from Wikipedia in the calculation!"
"Our research suggests that overall reverting activity in
Wikipedia is healthy and valuable,"
"there are
specific cases in which reverting activity might be managed
better"

"the reverting editor should be
encouraged to provide clear feedback to help the reverted
editor grow as a member of the community." // yeah. I bet this never happens
"Newcomers should be reached out
to actively to help them become socialized into Wikipedia."
"more curmudgeonly old-timers should be
kept away from newcomers until they have gained some ex-
perience in the system."
