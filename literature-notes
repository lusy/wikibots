\cite{DanaherEtAl2017}
# Danaher, J., Hogan, M. J., Noone, C., Kennedy, R., Behan, A., De Paor, A., et al. (2017). Algorithmic governance: Developing a research agenda through the power of collective intelligence:. Big Data & Society, 4(2), 205395171772655. http://doi.org/10.1177/2053951717726554


--> scrutinise effectiveness and legitimacy of algorithmic governance systems
--> propose a framework for researching these
--> "detailed map of key research themes, questions and methods" <-- vgl Latour
"The workshop brought together a multidisciplinary group of scholars to consider
(a) barriers to legitimate and effective algorithmic governance and
(b) the research methods needed to address the nature and impact of specific barriers."
--> "longer historical trend towards the mechanisation of governance"
--> "The systems we consider in this paper and
that we considered at our workshop are different from
their historical forebears. The differences are largely a
matter of degree and not of type."

top-down vs bottom-up algorithms: machine learning as an example of bottom-up: problem: lack of transparency, incorporated into already opaque governance structures

Checkout Kitchin research framework (p.5)

"Participants also suggested that we identify capacity-
related problems by analysing existing code and cate-
gorizing errors that emerge from this code according to
whether they are ‘technical’ or ‘legal’ in nature."

===================================================

\cite{MuellerBirn2014}

Aim:
- overview on various edit types bots carry out
- general reasons why wikipedia community uses bots
- how they organise machine tasks to provide a sustainable service

2 main groups:
- community services : create reports
- guidelines/policies : adding templates to pages

up-to-date (when?) 3 categories of research on bots:
- used as a tool for collecting data
- installed to reach Wikipedia editors in an automatic way to influence their
  editing behaviour
- bots considered as noise on the data/not important for further analysis

check Geiger(2009):
"how a weak but preexisting social norm was controversially reified into a
technological actor"

2010: 40% of newcommers' contributions rejected based on automatic tools <---
counter productive in engaging new contributors

attitudes towards bot usage changed over time
at the beginning: "One of Wikipedia's rules to consider: avoid using bots"
with time: more and more acceptance; beaurocracy; difficult for new commers to
engage

Overview: Bot Approval Group, Bot Policy, Requests for approval

methodology: select all approved task requests: try to infer bots' tasks from
them

statistics:
%TODO: check graphic in color
- proportion of bot edits grow compared to human editors

- bots edits are of support/maintenance nature
- a lot, compared to human edits, no content;
- at some point excluded from recent changes logs (is that so? today, they are
  there again, I'd say)

"Bots as community servers and rule enforcers"
"Bots are responsible that existing guidelines and policies are enforced at a
large scale."

%TODO: copy categories + conclusions from section 3.3
%TODO: literatur durchforsten

=======================================00

\cite{Geiger2017}

situated in critical algorithmic studies, critical data studies,
discusses issues in fairness, accountability and transparency

(algorithmic) governance
gatekeeping

"the organizational culture of Wikipedia is deeply intertwined with various data-driven algorithmic
systems, which Wikipedians rely on to help manage and govern the ‘‘anyone can edit’’ encyclopedia at a massive
scale."
"These bots, scripts, tools, plugins, and dashboards make Wikipedia more efficient for those who know how
to work with them, but like all organizational culture, newcomers must learn them if they want to fully participate."

Beschreibt die Prozesse für 2 verschiedene, oft vorkommende Edit-Abläufe:
* editting (your own) page on Wikipedia: Conflict of interest requests --> newcommers werden hier abgeschreckt
* Speedy Deletion

"But I realized that the more interesting question is why I had so internalized this socio-techni-
cal assemblage and the values it enacts." // People internalise the way a system works and stop questioning it!!

"They are deeply imbued with particular values, prin-
ciples, norms, and ideals, and learning them is not
just about technical competency, but also socialization
into a complex organizational culture"

Some descriptive statistics:
"In the English-language Wikipedia, 22 of the 25 most active editors (by
number of edits) are bot accounts, and July 2017, they made about 20% of all edits to encyclopedia articles."
--> vgl: https://quarry.wmflabs.org/query/20703

What does it take to be a Wikipedian:
"when that partici-
pation requires not only learning Wikipedia-specific
jargon, norms, style guides, and rules, but also learning
how to interact with all the bots and power tools"

"Wikipedia demonstrates how the issues in and around
algorithmic systems are as much social as they are tech-
nical, going far beyond the opacities that arise around
proprietary source code. My argument extends Burrell’s
(2016) discussion of three different forms of opacity in
machine learning: intentional secrecy (proprietary
source code), technical literacy (such as learning to
read code), and opacities inherent in machine learning
(such as issues of interpretability). To these forms, I add
another: the opacities in learning a particular institu-
tional or organizational culture that is supported by
algorithmic systems."
// source is open, but who can actually read it? and is willing to invest the time and energy in order to hold the system accountable?
// vgl auch Gedanke von Claudia: "Wikipedia is spannend, weil wir daran das erforschen können, was wir an Facebook nicht können. Und weil die ein Abbild der Gesellschaft im Kleinen ist."
// vgl auch Web Science def: observe micro behaviours in order to study macro phenomenons (governance, ..)

Def "algorithmic": "as involving encoded proced-
ures, which are typically—but not exclusively—compu-
tationally implemented."
