\cite{DanaherEtAl2017}
# Danaher, J., Hogan, M. J., Noone, C., Kennedy, R., Behan, A., De Paor, A., et al. (2017). Algorithmic governance: Developing a research agenda through the power of collective intelligence:. Big Data & Society, 4(2), 205395171772655. http://doi.org/10.1177/2053951717726554


--> scrutinise effectiveness and legitimacy of algorithmic governance systems
--> propose a framework for researching these
--> "detailed map of key research themes, questions and methods" <-- vgl Latour
"The workshop brought together a multidisciplinary group of scholars to consider
(a) barriers to legitimate and effective algorithmic governance and
(b) the research methods needed to address the nature and impact of specific barriers."
--> "longer historical trend towards the mechanisation of governance"
--> "The systems we consider in this paper and
that we considered at our workshop are different from
their historical forebears. The differences are largely a
matter of degree and not of type."

top-down vs bottom-up algorithms: machine learning as an example of bottom-up: problem: lack of transparency, incorporated into already opaque governance structures

Checkout Kitchin research framework (p.5)

"Participants also suggested that we identify capacity-
related problems by analysing existing code and cate-
gorizing errors that emerge from this code according to
whether they are ‘technical’ or ‘legal’ in nature."

===================================================

\cite{MuellerBirn2014}

Aim:
- overview on various edit types bots carry out
- general reasons why wikipedia community uses bots
- how they organise machine tasks to provide a sustainable service

2 main groups:
- community services : create reports
- guidelines/policies : adding templates to pages

up-to-date (when?) 3 categories of research on bots:
- used as a tool for collecting data
- installed to reach Wikipedia editors in an automatic way to influence their
  editing behaviour
- bots considered as noise on the data/not important for further analysis

check Geiger(2009):
"how a weak but preexisting social norm was controversially reified into a
technological actor"

2010: 40% of newcommers' contributions rejected based on automatic tools <---
counter productive in engaging new contributors

attitudes towards bot usage changed over time
at the beginning: "One of Wikipedia's rules to consider: avoid using bots"
with time: more and more acceptance; beaurocracy; difficult for new commers to
engage

Overview: Bot Approval Group, Bot Policy, Requests for approval

methodology: select all approved task requests: try to infer bots' tasks from
them

statistics:
%TODO: check graphic in color
- proportion of bot edits grow compared to human editors

- bots edits are of support/maintenance nature
- a lot, compared to human edits, no content;
- at some point excluded from recent changes logs (is that so? today, they are
  there again, I'd say)

"Bots as community servers and rule enforcers"
"Bots are responsible that existing guidelines and policies are enforced at a
large scale."

%TODO: copy categories + conclusions from section 3.3
%TODO: literatur durchforsten

=======================================00

\cite{Geiger2017}

situated in critical algorithmic studies, critical data studies,
discusses issues in fairness, accountability and transparency

(algorithmic) governance
gatekeeping

"the organizational culture of Wikipedia is deeply intertwined with various data-driven algorithmic
systems, which Wikipedians rely on to help manage and govern the ‘‘anyone can edit’’ encyclopedia at a massive
scale."
"These bots, scripts, tools, plugins, and dashboards make Wikipedia more efficient for those who know how
to work with them, but like all organizational culture, newcomers must learn them if they want to fully participate."

Beschreibt die Prozesse für 2 verschiedene, oft vorkommende Edit-Abläufe, mit den Bots und automatischen Tools, die diese unterstützen
* editting (your own) page on Wikipedia: Conflict of interest requests --> newcommers werden hier abgeschreckt
* Speedy Deletion

"But I realized that the more interesting question is why I had so internalized this socio-techni-
cal assemblage and the values it enacts." // People internalise the way a system works and stop questioning it!!

"They are deeply imbued with particular values, prin-
ciples, norms, and ideals, and learning them is not
just about technical competency, but also socialization
into a complex organizational culture"

Some descriptive statistics:
"In the English-language Wikipedia, 22 of the 25 most active editors (by
number of edits) are bot accounts, and July 2017, they made about 20% of all edits to encyclopedia articles."
--> vgl: https://quarry.wmflabs.org/query/20703

What does it take to be a Wikipedian:
"when that partici-
pation requires not only learning Wikipedia-specific
jargon, norms, style guides, and rules, but also learning
how to interact with all the bots and power tools"

"Wikipedia demonstrates how the issues in and around
algorithmic systems are as much social as they are tech-
nical, going far beyond the opacities that arise around
proprietary source code. My argument extends Burrell’s
(2016) discussion of three different forms of opacity in
machine learning: intentional secrecy (proprietary
source code), technical literacy (such as learning to
read code), and opacities inherent in machine learning
(such as issues of interpretability). To these forms, I add
another: the opacities in learning a particular institu-
tional or organizational culture that is supported by
algorithmic systems."
// source is open, but who can actually read it? and is willing to invest the time and energy in order to hold the system accountable?
// vgl auch Gedanke von Claudia: "Wikipedia is spannend, weil wir daran das erforschen können, was wir an Facebook nicht können. Und weil die ein Abbild der Gesellschaft im Kleinen ist."
// vgl auch Web Science def: observe micro behaviours in order to study macro phenomenons (governance, ..)

Def "algorithmic": "as involving encoded proced-
ures, which are typically—but not exclusively—compu-
tationally implemented."

"Like all algorithmic systems, the ones I studied in
Wikipedia were designed, developed, and deployed by
people." //all developers are human and all humans make mistakes^^

"As Gillespie (2014) argues: ‘‘A socio-
logical analysis must not conceive of algorithms as
abstract, technical achievements, but must unpack the
warm human and institutional choices that lie behind
these cold mechanisms.’’"

Seaver (2013: 9–10) Def Algorithmic System:
"It is not the algorithm, narrowly defined, that has
sociocultural effects, but algorithmic systems — intri-
cate, dynamic arrangements of people and code. . .
When we realize that we are not talking about algo-
rithms in the technical sense, but rather algorithmic
systems of which code strictu sensu is only a part,
their defining features reverse: instead of formality,
rigidity, and consistency, we find flux, revisability,
and negotiation."
"In this context, I ask: for whom are algorithmic systems
(and the organizations that rely on them) formal, rigid,
and consistent, and for whom are they in flux, revisable,
and negotiable?" //Vorwissen, das die Menschen mitbringen, ist wichtig!

2nd level digital divide:
"who had
the knowledge, skills, and sense of empowerment to use
the Internet in ways that further engaged, empowered,
and benefitted their lives." nach Hargittai 2002

Everything's open:
"We must look at more than the fact that partici-
pation in Wikipedia is open to the public; that the infra-
structure supporting it is open sourced; and that the
community’s policies, procedures, and norms are docu-
mented in thousands and thousands of pages of text."

BUT
"We must also look at what kind of skills, knowledge, and
investment is required to fully and successfully partici-
pate,"

speaks of deletion of substandard encyclopedi articles: Where and how are the standards defined? Who defines them?

"article about a
website fails the A7 criteria in the CSD process,
which demands that articles ‘‘credibly indicate the
importance or significance of the subject.’’ (A majority
of speedy deleted articles are tagged with templates
containing A7 rationales (Geiger and Ford, 2011).)"
// ich finde dieses Kriterium ist äußerst mit Vorsicht zu genießen, da die Tür weit aufgemacht wird für Sexismus, Rassismus und andere Arten von Diskriminierung von Inhalten, die der Mehrheit von white dudes nicht passen

"Yet I had a
second, subtler motivation, hoping that in properly
demonstrating correct usage of such a template within
the established workflow of this process, I would be
made legible as a Wikipedian who knew the CSD pro-
cess and should be given some more leeway—unlike
most of the people who were creating articles that
they were deleting." //making use of the brocode^^

"Such systems do not eliminate the need for human
labor, but instead transform the kind of work that
takes place,"

erwähnt auch Abschrecken von newcommers

"As
Seaver (2013) notes with his critiques of various ‘‘crit-
ical algorithms studies’’ literature, it is easy to slip into
a mode of analysis where social factors are contextua-
lized, while infrastructure remain static and determin-
ing. Such an approach ‘‘keeps algorithms themselves
untouched, objective stones tossed about in a roily
social stream’’ (10)."

"the algorithmic
systems themselves are constructed, negotiated, contex-
tualized, and differently interpreted and enacted." // aber wer kann beim Aushandeln mitmachen?

"Wikipedia’s computational infrastructure is
also designed and governed in a relatively open
manner by the project’s volunteer community of edi-
tors (Forte and Bruckman , 2008; Gilbert and Zachry,
2015; Kennedy, 2010), unlike most of the automated
systems that are increasingly prevalent in digitally
mediated environments." //jup. und selbst da blick man nicht durch

Requirements/Expectations for bot developers:
"bot developers are generally expected to be responsive
to reasonable requests and concerns from the
community."

"Wikipedians discuss and debate
about what kinds of bots should exist in the project,"

"one of the
paradoxes of openness is that it can take substantial
time, energy, investment, and resources to fully take
advantage of all the materials released"

Veterans vs newcomers:
"they make it far easier for veteran Wikipedians to
engage in the kind of specific, complex, multifacted
work involved in the governance of Wikipedia. This
can make it far more difficult for newcomers to partici-
pate—not necessarily because bots, algorithms, or
assisted tools are inherently difficult to deal with, but
rather because bots support more complex kinds of gov-
ernance practices in Wikipedia, and complex govern-
ance practices are difficult for newcomers."

=========================================

\cite{GeiHal2017}

replicate + refute earlier results (of the paper "Even Good Bots Fight")
methods: combi: qualitative + quantitative
trace ethnography: "seek to understand data in the context it has within a community of practice," "data to be a starting point for further contextualization and interpretation,"
operationalise conflict!
distinguish conflict from non-conflict in bot reverts
compile data set + meta data
background: wikipedia researchers + long-time contributors
findings: overwhelming majority of the reverts are routine collaborative work between bots
metrics: time between reverts; number of reverts per article for the same bot pair
in addition: in depth analysis of random examples from different parts of the statistical distribution of the metrics
classify patterns in edit summaries

research question: "to what extent are bot-bot reverts
in Wikipedia genuine conflicts where disagreements about how Wikipedia ought to be written were
embedded in opposing bot codebases, versus cases like Shoreland’s Addbot that reflect the opposite?"

Out of context Addbot's edits seem like a bot ran rampart.
In context it's been tons of useful work.
Do not tear data out of context!

"The EGBF paper operationalized
bot-bot conflict through reverts, which is when one user account undoes another user account’s
edit." // Geiger+Halfaker operationalisieren den Begriff differenzierter

Literature Review: bis dato Arbeiten zu bot feedback; und criticism about driving away newcomers; aber keine Forschung hat Revert Wars thematisiert;

conflict: not necessary negative, but can be generative and stimulating (avoid filter bubbles) if resolved in a respectful manner

Conflict typology:
task conflict
process conflict
relationship conflict

Types of reverts:
identity revert: "as bringing it back to an exact previous state"
partial revert: "part of an edit is removed"
declarative revert: "when a user leaves a note in an edit summary stating that they are reverting the edit (matching “rv” or “revert”)."
-> Work based on identity reverts

"They note a single revert is not indicative
of conflict, but repeated back-and-forth reverts are indicative of an edit war"

"The “Bold, Revert, and Discuss”
cycle (one of the most widely-cited essays [31] in English Wikipedia) states that editors ought to
be bold in making changes, feel free to revert others’ changes that they find unacceptable, then
discuss the issue" // kommt mir iwie netter vor, erst zu diskutieren, dann zu löschen

Types of conflicts:
* bot-bot conflict: bots are programed with opposing directives --> not many cases found
* conflict about bots: human editors in conflict over what bots ought to be developed --> many cases found, conflict not limited to discussions about bots though, part of day-to-day work on Wikipedia
* sometimes conflict turns interpersonal

Check Geiger "Lives of bots" for history of Bot Policy;

"Unapproved bots are not allowed to edit encyclopedia
articles; they must get prior approval from the BAG for a specific, well-defined task."
"Operators of approved
bots are also obligated to respond to issues and concerns raised to them, and failure to do so can
get a bot’s approval revoked by the BAG."

Claudia's paper:
"“In both cases of algorithmic governance
– software features and bots – making rules part of the infrastructure, to a certain extent, makes
them harder to change and easier to enforce” (p. 87)"

"Dozens of language versions of Wikipedia have their own bot policy and bot ap-
proval process or group (which are generally modeled on English Wikipedia), including Japanese,
Italian, French, Romanian, Portuguese, Spanish, Japanese, and Mandarin Chinese. There is also a
much stricter global bot approval process for the smaller language versions that do not have their
own bot approval process (similarly modeled English Wikipedia),"

"when working with large-scale “found data” [36] of the traces
users leave behind when interacting on a platform, how do we best operationalize culturally-specific
concepts like conflict in a way that aligns with the particular context in which those traces were made?"

iterative mixed method
combination of:
* quantitative methods: mining big data sets/computational social science
"begin with one or
more large (but often thin) datasets generated by a software platform, which has recorded digital
traces that users leave in interacting on that platform. Such researchers then seek to mine as much
signal and significance from these found datasets as they can at scale in order to answer a research
question"
* more traditional social science/qualitative methods, e.g. interviews, observations, experiments

beware of decontextualisation! (the problem with the Even Good Bots Fight paper)
All models are wrong but some of them are useful.
"There is inevitably something left behind or incompletely captured in any transcription or
translation of an entity or event in the world [10, 42, 70]."

Star: "ethnography of infrastructure":
"discusses the “veridical” approach, in which “the information system
is taken unproblematically as a mirror of actions in the world, and often tacitly, as a complete
enough record of those actions” (p. 388).
She contrasts this with seeing the data as “a trace or record
of activities,” in which the information infrastructure “sits (often uneasily) somewhere between
research assistant to the investigator and found cultural artifact."

"At the
broadest level, this paper is about how to cook and prepare a dataset with care."

Generating data set: all edits till 2016? with all meta data.
("The dataset released by the EGBF authors only
ranges from 2001-2010, does not contain full metadata for each edit, and was generated by software
code that is not publicly available.")

Identifying bot accounts:
* bot user group (limitations: bots get frequently removed from/unflagged when they are no longer active)
* user_former_groups : former bots
* "Bot user" cross-wiki category
--> 6522 current and former bots identified across all language versions

Identify reverts with: https://github.com/mediawiki-utilities/python-mwreverts

"bot-bot reverts grew and peaked in 2013 across all languages, then have
declined since."

fast reverts: more likely to constitute a conflict
consensus can change: bots make articles comply with new policies in bulk

"we found a substantial amount of
bot-bot reverts were undoing an edit the other bot had made months, even years after."
median time to revert: 62 days; and it's been rising over time

"decreased incidents of bot-bot conflict as various language
versions gained stronger and more established bot policies and bot approval venues."

"93.2% of
bot-bot reverts were not reciprocated or other-
wise responded to by the bot that was reverted."
"our max was
two cases where the same two bots each re-
verted the other 41 times on the same article."

"What kinds of work are these bots were doing?
What were the bot’s developers intending the bots to do?"

"Trace
ethnography is not “lurker ethnography” done by someone who never interviews or participates in
a community."
trace literacy --> get to know the community; know how to participate in it

What are the traces they looked at:
- start with the revision ID of an identified bot-bot revert
- follow other traces to find other contextual information, such as:
  - what was changed in the revert,
  - the bot developer’s summary of what the bot was doing at the time,
  - the other edits that both bots had made,
  - both bots’ Requests for Approval before the Bot Approvals Group (if any),
  - the various talk pages where Wikipedians would raise and resolve the conflict (in cases of genuine conflict),
  - and the various policies and guidelines in force at the time of the revert.

"we know what does not get captured in logs and revision histories;"

thick description of different prototypical cases:
Non-conflicts:
- fixing double redirects (see paper for details):
  - task carried on by a lot of bots (code for that also provided in the pywikibot framework)
- removing interwiki links? (since lining between language version got exported to Wikidata)
- updating of article notification templates (page is protected from editing or has some issue; template removed when the issue is resolved)
- moving categories
- editing "per" justification: "single purpose bots that are written to implement a decision reached
by Wikipedians that applies to many articles in a category or even across the encyclopedia." --> may be reverted when consensus change again

Conflicts - specific cases:
- Mathbot and Frescobot over link syntax.
  - no fundamental disagreement between developers about what ought to be done
  - bots still programmed with opposing tasks
  - took over 2 years before it was noticed
- Mathbot's disambiguation links
  - conflict/disagreement between Wikipedians about: first task, then process and at the end it also turned to interpersonal for some people
- Archiving links: AnomieBot vs CyberBot II.
  - 41 revert sequence on a single page over the course of only 4 days,
  - most intensive bot-bot revert war in our dataset in terms of reverts per page per day
  - task conflict; one of the bots had a bug

classify patterns in edit summaries
(NOTE: "However, these
summaries are records of what the bot developer has programmed the bot to say the edit is doing
(as opposed to what the bot is actually doing).")
- grouping edits by reverting comment and counting the most frequently occurring comments
- ounting the most commonly occurring words and n-grams in comments.

Conclusion:
"We found that the overwhelming majority of bot-bot reverts on articles are better characterized as
routine, productive, and even collaborative work between bots."
edit wars < 4% of reverts (more like 0.5%)

bot governance: similar to article governance

-What-Who is a bot? --> Bot Def!!
"for us, bots are inextricably linked to their developers, rather than autonomous agents who can
be studied independently of the people who develop and operate them. Speaking to this, many
Wikipedia bot developers name their bot not after the task it does, but after themselves: CydeBot
is run by a user named Cyde, Addbot is run by Adam Shoreland (whose username is Addshore),
CyberBot is run by a user named Cyberpower678, Xqbot is run by a user named Xqt, and more."

"the actual programming of the bot to complete a particular task is only a part of what bot developers do"
"there is also a substantial amount of social-organizational work that takes place behind the scenes"
"must speak and advocate for their bots in the Wikipedia community, which is a requirement of
the bot policy."
"Bot developers make proposals to the Bot Approvals Group, respond to issues and
concerns from BAG members and other Wikipedians before and after approval,"
"Bot developers who do not sufficiently respond to issues raised about
approved bots are liable to having their bots blocked."

assemblages:
"entirely different question to ask about the dynamics of conflict
when we see bots as assemblages of code and a human developer/advocate, who is responsible for
operating the bot in alignment with Wikipedia’s complex policy environment."

what bots should be created is an epistemological issue

data do not speak for themselves! context needed -> membership in a community of practice

English is the primary language of both authors, limited understanding of other language versions

====================================================

{IliadisRusso2016}

overview article

big data is not neutral but instead consists of already constituted assemblages

"Data are a form of power."
"lack of data is another indication of power, the power
not to look or to remain hidden (Brunton and
Nissenbaum, 2015; Flyverbom et al., 2016)."
"foreground data’s power structures"

current research trends: positivist approach (and not critical)

"Data, along with its sciences and infrastructures, are informed
by specific histories, ideologies, and philosophies that
tend to remain hidden, though there have been recent
calls for inquiry into these domains (Beer, 2016; boyd
and Crawford, 2012; Crawford et al., 2014; Floridi,
2011; Kitchin, 2014, 2015)"

"Big Data are
susceptible to losing provenance and their ability to be
‘‘about’’ only one thing, their origins and interpret-
ations becoming multiple and conflicting as metadata
are mixed with primary, secondary, and derivative
data."
-> data disorder
-> potential for harm to data subjects

Def:
"critical approach to Big Data
investigates meta-theoretical modes of conversation
and styles of scientific thinking"
"analyzes the
ground upon which positivistic Big Data science stands."
"How do Big Data inflect and interact with society,"
"CDS has emerged as a loose knit group of
frameworks, proposals, questions, and mani-
festos"
"What need to be established are long-term projects"

data assemblages:
"CDS should study ‘‘data assemblages,’’ that is ‘‘the
technological, political, social and economic appara-
tuses and elements that constitutes and frames the
generation, circulation and deployment of data’’ (1)." (Kitchin, Lauriault 2014)
"The
apparatus and elements of a data assemblage may
include systems of thought, forms of knowledge,
finance, political economy, governmentalities and leg-
alities, materialities and infrastructures, practices,
organizations and institutions, subjectivities and com-
munities, places, and the marketplace where data are
constituted."
"Data assemblages are the powerful complex of entities
that form the underlying production of Big Data sci-
ence at multiple levels of abstraction and in a plurality
of domains."

"CDS follows three basic principles derived from this
broadly Aristotelean approach: the identification of
social data problems, the design of critical frameworks
for addressing social data problems, and the applica-
tion of social solutions to increase data literacy."

=================================================

\cite{GeiRib2011}

- Define/Present the methodology of trace ethnography
- Illustrate it using the case study of tracing/banning vandals on wikipedia


Def
"combines the richness of participant-observation
with the wealth of data in logs so as to reconstruct
patterns and practices of users in distributed
sociotechnical systems."

"integrates and extends
a number of longstanding techniques across the social
and computational sciences"

"exploits the proliferation of
documents and documentary traces"

"traces not only
document events but are also used by participants
themselves to coordinate and render accountable many
activities"

"heterogeneous data – which include transaction logs,
version histories, institutional records, conversation
transcripts, and source code"
"allowing us to retroactively reconstruct specific actions
at a fine level of granularity"

"sets of
such documentary traces can then be assembled into
rich narratives of interaction"

"turn thin documentary traces into
“thick descriptions” [10] of actors and events"

extends/assembles various existing methods to counteract the common concern with the limitations of traditional single-sited participant observation

"explicitly or implicitly,
documentary traces are the primary mechanism in
which users themselves know their distributed
communities and act within them."

"traces can only
be fully inverted through an ethnographic
understanding of the activities, people, systems, and
technologies which contribute to their production."

traditional ethnographic observation is costly and inpractical in distributed settings (and may miss phenomena that occur between sites)

Strategies for studying distributed systems:
- study documentary practices
"trails of correspondence
between scientists [24,26], the manuals and handbooks
that seek to harmonize practice within corporate
organizations [22], trading records in global financial
markets[15], or the standards and protocols that guide
technology development and use [5]"
"often the case even in
traditional co-located organizations."

following workers around (traditional ethnographic observation) -> following documents around
"following these documents as they travel
across the site, asking how, where, and by whom they
are produced, edited, revised or filed"
"By focusing
on the lifecycles of these documents, the researcher is
able to follow workflows of activity across an
organization"

- participant-generated ethnography
"having participants capture their own qualitative data"
user-authored diaries or journals
plus: "balance the need for rich,
thick, and highly-empirical data with the practical
limitations involved with performing ethnographic
fieldwork,"
minus: "on its
own, it lacks the same holistic understanding gained
though ethnographic observation."
"there may be entire swaths
of activity that are left of these logs (whether because
they are embarrassing for recorders, or simply
considered too mundane to be worth mentioning)."

- historical and archival ethnography (vgl Challenger Bsp)

- Multi-Sited Ethnography (‘Follow the Actors’)
"especially around topics like
globalization, migration, nationalism, and other issues
that are not typically present in a single site."
"researcher travels to multiple sites"
NOTE: "visiting multiple
sites is intended not to give the ethnographer more
cases, (i.e. for a broader or more representative
sample), but to expand a single case beyond its
immediate location."
ANT: follow the actors (mobile populations, materials, stories, ideologies, metaphors, conflicts)

- Strategically-situated ethnography
be at the right place at the right time
"Instead of
trying 'to be everywhere' in a large network
[...]
deliberately situated themselves at the particular times
and places where a system is being designed,
constructed, contested, broken, or repaired [25]."
"identify the most relevant, important, or
representative local sites in a distributed organization,"

"In studies of science, focusing on a moment of
controversy can be particularly revealing, as expert
participants pick apart each others’ evidence and
arguments [7]."

"most heavily relying logs
and records that are automatically generated in digital
environments"
--> especially in software platforms for the production and distribution of content, zB:
"blogs, wikis, source code repositories,
content management systems (CMS),"

"who changed what to a
document and when, so that an author can
reconstruct the history of a document"

Understanding codes!
"Embedded within these
archival records of who changed what and when, we
found a wide variety of codes that we initially passed
over, seeing them as either incomprehensible markup
or relatively non-descriptive"
"Like all codes, they are
sociotechnical, and therefore their meaning can only be
understood in relation to their broader cultural and
computational systems"

Critique:
"it only can observe what the system
or platform records, which are always incomplete."

Case study: tracing vandals in Wikipedia
Inverting the traces:
- collect MediaWiki revision data (for a single user)
- analyse edit-summary fields (used sparsely by humans, but extensively by bots and tools in a regular fashion)
- pay special attention to markers (codes): observe users that leave them, try to understand when are they used
- look around for documentation
- try out the semi-automatic software tools for themselves to get a understanding of what tasks they perform and what traces are generated along the way (these tools generally prescript narrow paths of action)

"Becoming familiar with traces requires both
immersion in the average, everyday affairs of a group
and active investigation of otherwise backgrounded
actors, software, and data."

the tools (Huggle and Twinkle) issue warnings with automatically decided warning level

1) initial ethnographic fieldwork: identify routines
2) locate/aggregate via documentary analysis
3) assemble a chain of activity

bsp of Wikipedians inverting the traces themselves for a disciplinary hearing about a conflict between admins

Limitations:
"the methodology described does
not tell us how the organizational routine of four
escalating warning was originally developed and
implemented, or the attitudes vandal fighters hold
towards it."

Concerns:
- ethical: breaching privacy via thickening the traces; no possibility for informed consent

====================================================================

\inproceedings{ButJoyPi2008}

wikis allow for a wide range of structures

aim of the paper: "to propose and apply a conceptual framework for
understanding the natures and roles of policies in wikis"

"one of the founding principles of
Wikipedia is “Ignore all rules,” which states that if a rule
inhibits developing Wikipedia, the contributor should
ignore it [45]."

Stand Sept. 2007 (EN Wikipedia) TODO: vgl mit heute
* 44 pages in the "Wikipedia Official Policy" category
* 248 in "Wikipedia Guidelines"
* 45 pending proposals for guidelines and polcies
* 200 rejected proposals for guidelines and policies

study concentrates on formal (written) norms
* easier to study, because explcit
* versions, discussions on them a written
* serve as boundary objects
* often sites of conflict (because are explicit and visible)

use rules/policies/guidelines interchangeably
vgl Wikipedia def:
"“A guideline is any page that is: (1) actionable (i.e. it
recommends, or recommends against, an action to be taken
by editors) and (2) authorized by consensus. Guidelines are
not set in stone and should be treated with common sense
and the occasional exception.
A policy is similar to a guideline, only more official and
less likely to have exceptions.” [48]"

aufbau: walk through different purposes/wahrnehmungen of rules and policies
(drawn from prior work) and illustrating how each of them applies to Wikipedia
1. Rules and Policies as Rational Efforts to Organize or Coordinate
2. Rules and Policies as Evolving, Competing, Self-propagating Entities
3. Rules and Policies as Constructions of Meaning and Identity
4. Rules and Policies as External Signals
5. Rules and Policies as Internal Signals
6. Rules and Policies as Negotiated Settlements and Trophies
7. Rules and Policies as Control Mechanisms

1.)
"All groups are faced with challenges created by
communication and coordination problems"

Def Rules:
"rules are conscious, intentional
actions put in place for the purpose of improving collective
performance."

"assume that all parties have the same motivations and goals"

"important in contexts
where there is high turnover (people coming and going on a
regular basis), where there is substantial autonomy of
action, and where explicit coordination is costly"

=in Wikipedia=
* high turnover
* editors distributed globally
* coordination necessary
* policies and guidelines to achieve reliability and consistency
* policies and guidelines confirm the authority of the administrators
* administrators: the authority most likely to implement the policies
* witten polcies and guidelines needed to facilitate and transfer knowledge
* fewer policies specified for administrators than users
* administrators change not as frequent as users
* written policies ensure coordination and prevent arbitrary decisions
* no need for lengthy discussions and consensus seeking for each decision

2.)
check ich nicht ganz^^, paar zitate:
"This perspective
rejects the idea of intention, design, and agency as the
primary drivers of policy development, largely because of
the bounded rationality of individuals and high levels of
complexity in the organizational system."

"rules are the result of competition for shifting
attention"

"rules generate more rules"

=in Wikipedia=
"For Wikipedia, the basic conditions of this perspective
definitely apply."
"extremely complex system
of documents, people, roles, policies and guidelines, yet
individuals possess bounded rationality"
"All policies studied grew enormously."

"attempts to take the complex system that is Wikipedia and
make it manageable"
"promotes the continuous updating and modification of
rules"

3.) Rules and Policies as Constructions of Meaning and
Identity

"answer questions about “who we are”"
"indicate the way things “should be” (i.e.,ideals)"
"Rules in this role allow the wiki and its users to develop a
sense of identity and meaning"

=in Wikipedia=
* define what Wikipedia is and is not (explicitely or through policy pages on
  community principles, such as Ignore All the Rules)
* identity construction reflected in discussions of policy changes, whether or
  not smth is consistent with the "core principles" (example: discussion around
  the Neutral Point of View Policy)
* Wikipedia is NOT
  * printed and published encyclopedia written by paid experts
  * a bureaucracy :P
* disagreement should be resolved through a consensus based discussion
* lays out explicitely norms for community behaviour
* "Follow the spirit, not the letter, of
any rules, policies and guidelines if you feel they conflict."

4.) Rules and Policies as External Signals
"Sometimes rules are ways of indicating to outside
stakeholders or concerned parties that things that they care
about are being attended to."

=in Wikipedia=
* Bsp: Copyrights policy
"it appears they were developed in
response to external complaints or concerns about the
unpermitted use of protected material [47]"
"The language evolved from simple sentence
structures and vernacular style into the more complicated
grammars and dictions of the legal profession, possibly due
to the hiring of general counsel"
"pressures to protect itself and its reputation from outside
attacks or influences."

* another example: Biographies of living persons policy
"It includes full contact information for Jimmy Wales as
the “Designated Agent” (which references specific
requirement of US Law)"
"explicitly references external legal structures
requirements"
"very insistent language"
"In internal discussions, explanations for the policy and
changes to the policy are described in the third person"
"external attention triggers changes"
"The policy is referenced in statements to external
stakeholders and media."

"demonstrating that the
wiki and its members recognize an issue as important or
significant."

"rules which
act as external signals speak to external audiences and are
not necessarily meant for internal audiences, or members."

5.) Rules and Policies as Internal Signals
"signal to the community
what the community finds important,"

=in Wikipedia=
* bsp Civility Policy (promote polite interactions between members)
* "Policies fitting into this category are not
threatened by outside forces, so their language can remain
less formal"

"triggered by either internal members (e.g. via complaints or
problematic events) or external viewers."

6.) Rules and Policies as Negotiated Settlements and
Trophies

"People have different interests or perspectives"
"Settlements
are creating to avoid the cost of continued conflict, while
trophies are created to give credibility and influence to the
“winner” in future discussions."

=in Wikipedia=
* references to that which "has already been decided"
* bsp Consensus Policy (lenghty description, people referring to smth 
  previously decided)
* prevents continuous recycling of old fights and unresolved contentions

"The
question then arises is how large must the majority be to
ignore the opinions of a minority?”"

7.) Rules and Policies as Control Mechanisms
"Control is
defined as any effort made to ensure appropriate action"

"attempts to ensure that individuals on a project team act in
accordance with a previously agreed-upon strategy to
accomplish desired goals and objectives"

"formal modes control via performance
evaluation and rewards while informal modes control via
socialization to reduce goal differences"

"rules are used to
manage divergence of individual and organizational goals"

=in Wikipedia=
* hierarchy of roles: the administrator class applies control mechanisms for
  the group
* sometimes claimed this hierarchy doesn't exist
* sometimes individuals have distructive goals (i.e. vandalism)
* in such cases policies like Blocking prevent chronic disrupters from damaging
  group efforts
* policies "encourage" appropriate behaviour
* Three-Revert Rule (No more than 3 changes to a page within 24h) to prevent
  edit wars

Conclusions
"pursuing the “policyless” ideal
that wikis represent is a pipedream. Policy creation and
maintenance is an important aspect of the work that must be
done to keep the community running"

* there are pitfalls, if policies and regulation mechanisms are directly
  embedded into the software
"Since policies can also be highly
symbolic or meaning-filled, embedding them or automating
them may not work because it could remove this function or
make it less effective for this purpose."

==================================================

\cite{MueDoHer2013}

2 categories of governance mechanisms: social and algorthmic
* social: based primarily on communication; social norms are often formalized by
written rules and guidelines
* algorithmic: "techical infrastructure that enables users to access artifacts"
"hat allows
the community to communicate and coordinate their collective ac-
tions to create those artifacts."

Research question: "how a community’s
consensus gradually converts social mechanisms into algorithmic
mechanisms."

Analyse algorithmic governance mechanisms for "flagged revisions" and "xqbot"

Aims of the paper:
"(1) characterizing social and algorithmic governance
mechanisms,
(2) discussing implementations of algorithmic gover-
nance mechanisms,
(3) presenting examples of how existing
social mechanisms are successively manifested in the technical in-
frastructure by converting them into algorithmic mechanisms."

"the community gradually transfers “rights to rule” to bots"

Governance def: "From a strategic management perspective, Williamson defines
gov-
ernance as the creation of order to achieve mutual gains in poten-
tially conflict-laden contexts [39]"
"A carefully negotiated and balanced set of rules
is required to ensure the long-term survival of such commons-based
governance regimes [22]."

participation in FLOSS projects highly dependent on the governance structures

governance regime -> dynamic phenomenon
"community’s perception of its governance regime
may change over time [16]."
"communities are likely
to introduce bureaucratic mechanisms into a stabilized governance
regime, which would have been unthinkable in earlier phases"
"On an individual level, [...] artifacts [...] are important in terms of their role as
a coordination mechanism"

Components of a governance regime:
(1) structures and processes, (2)
informal, formal, and encoded rules, (3) externally applied as well
as internalized rules, and (4) mechanisms of both trust and verifi-
cation/control” [18].

Different views on governance in Wikipedia (check also Schoeder and Wagner[24])
* comparably egalitarian and participatory governance
* bureaucratic features
* "strict hierarchical content management system"

changed substantially over time
